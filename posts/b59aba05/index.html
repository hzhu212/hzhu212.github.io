<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.jpg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hzhu212.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.23.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"trigger":"auto"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="本文为 概率统计讲义 一书的笔记。">
<meta property="og:type" content="article">
<meta property="og:title" content="概率统计笔记">
<meta property="og:url" content="https://hzhu212.github.io/posts/b59aba05/index.html">
<meta property="og:site_name" content="Henry&#39;s Blog">
<meta property="og:description" content="本文为 概率统计讲义 一书的笔记。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2019-06-15T11:00:49.000Z">
<meta property="article:modified_time" content="2025-04-07T06:10:19.270Z">
<meta property="article:author" content="Henry">
<meta property="article:tag" content="概率统计">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://hzhu212.github.io/posts/b59aba05/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://hzhu212.github.io/posts/b59aba05/","path":"posts/b59aba05/","title":"概率统计笔记"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>概率统计笔记 | Henry's Blog</title>
  








  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.1/dist/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"O49O3LRqDf6XCiPXdKzeqKGp-gzGzoHsz","app_key":"XcrzmNEzlES5k9h5BDN3oKpb","server_url":null,"security":false}</script>
  <script src="/js/third-party/statistics/lean-analytics.js" defer></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="Henry's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Henry's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">用简单的话把事情讲明白</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-%E9%9A%8F%E6%9C%BA%E4%BA%8B%E4%BB%B6%E4%B8%8E%E6%A6%82%E7%8E%87"><span class="nav-number">1.</span> <span class="nav-text">第一章 随机事件与概率</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%91%E7%8E%87"><span class="nav-number">1.1.</span> <span class="nav-text">频率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A6%82%E7%8E%87"><span class="nav-number">1.2.</span> <span class="nav-text">概率</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AD%89%E6%A6%82%E5%AE%8C%E5%A4%87%E4%BA%8B%E4%BB%B6%E7%BB%84"><span class="nav-number">1.2.1.</span> <span class="nav-text">等概完备事件组</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%8B%E4%BB%B6%E7%9A%84%E8%BF%90%E7%AE%97"><span class="nav-number">1.2.2.</span> <span class="nav-text">事件的运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%8B%E4%BB%B6%E7%9A%84%E4%BA%92%E4%B8%8D%E7%9B%B8%E5%AE%B9%E6%80%A7"><span class="nav-number">1.2.3.</span> <span class="nav-text">事件的互不相容性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A6%82%E7%8E%87%E7%9A%84%E5%8A%A0%E6%B3%95%E5%85%AC%E5%BC%8F"><span class="nav-number">1.2.4.</span> <span class="nav-text">概率的加法公式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87"><span class="nav-number">1.2.5.</span> <span class="nav-text">条件概率</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A6%82%E7%8E%87%E7%9A%84%E4%B9%98%E6%B3%95%E5%85%AC%E5%BC%8F"><span class="nav-number">1.2.6.</span> <span class="nav-text">概率的乘法公式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%8B%E4%BB%B6%E7%9A%84%E7%8B%AC%E7%AB%8B%E6%80%A7"><span class="nav-number">1.2.7.</span> <span class="nav-text">事件的独立性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%A8%E6%A6%82%E5%85%AC%E5%BC%8F"><span class="nav-number">1.2.8.</span> <span class="nav-text">全概公式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%86%E6%A6%82%E5%85%AC%E5%BC%8F"><span class="nav-number">1.2.9.</span> <span class="nav-text">逆概公式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%8B%AC%E7%AB%8B%E8%AF%95%E9%AA%8C%E5%BA%8F%E5%88%97%E6%A6%82%E5%9E%8B"><span class="nav-number">1.2.10.</span> <span class="nav-text">独立试验序列概型</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E4%B8%8E%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83"><span class="nav-number">2.</span> <span class="nav-text">第二章 随机变量与概率分布</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F"><span class="nav-number">2.1.</span> <span class="nav-text">随机变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F"><span class="nav-number">2.2.</span> <span class="nav-text">一、离散型随机变量</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83"><span class="nav-number">2.2.1.</span> <span class="nav-text">常用的离散型随机变量的概率分布</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E8%BF%9E%E7%BB%AD%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F"><span class="nav-number">2.3.</span> <span class="nav-text">二、连续型随机变量</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0"><span class="nav-number">2.3.1.</span> <span class="nav-text">概率密度函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0"><span class="nav-number">2.3.2.</span> <span class="nav-text">常见概率密度函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0"><span class="nav-number">2.3.3.</span> <span class="nav-text">分布函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%87%BD%E6%95%B0%E7%9A%84%E5%88%86%E5%B8%83"><span class="nav-number">2.3.4.</span> <span class="nav-text">随机变量函数的分布</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%87%BD%E6%95%B0%E7%9A%84%E5%88%86%E5%B8%83"><span class="nav-number">2.3.4.1.</span> <span class="nav-text">离散型随机变量函数的分布</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%BF%9E%E7%BB%AD%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%87%BD%E6%95%B0%E7%9A%84%E5%88%86%E5%B8%83"><span class="nav-number">2.3.4.2.</span> <span class="nav-text">连续型随机变量函数的分布</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81"><span class="nav-number">3.</span> <span class="nav-text">第三章 随机变量的数字特征</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%9C%9F%E6%9C%9B"><span class="nav-number">3.1.</span> <span class="nav-text">随机变量的期望</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%9C%9F%E6%9C%9B"><span class="nav-number">3.1.1.</span> <span class="nav-text">离散型随机变量的期望</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%87%A0%E4%B8%AA%E5%B8%B8%E7%94%A8%E5%88%86%E5%B8%83%E7%9A%84%E6%9C%9F%E6%9C%9B"><span class="nav-number">3.1.1.1.</span> <span class="nav-text">几个常用分布的期望</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9E%E7%BB%AD%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%9C%9F%E6%9C%9B"><span class="nav-number">3.1.2.</span> <span class="nav-text">连续型随机变量的期望</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%87%A0%E4%B8%AA%E5%B8%B8%E7%94%A8%E5%88%86%E5%B8%83%E7%9A%84%E6%9C%9F%E6%9C%9B-2"><span class="nav-number">3.1.2.1.</span> <span class="nav-text">几个常用分布的期望</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%9F%E6%9C%9B%E7%9A%84%E7%AE%80%E5%8D%95%E6%80%A7%E8%B4%A8"><span class="nav-number">3.1.3.</span> <span class="nav-text">期望的简单性质</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%87%BD%E6%95%B0%E7%9A%84%E6%9C%9F%E6%9C%9B"><span class="nav-number">3.1.4.</span> <span class="nav-text">随机变量函数的期望</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="nav-number">3.2.</span> <span class="nav-text">随机变量的方差</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="nav-number">3.2.1.</span> <span class="nav-text">离散型随机变量的方差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9E%E7%BB%AD%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="nav-number">3.2.2.</span> <span class="nav-text">连续型随机变量的方差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E5%88%86%E5%B8%83%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="nav-number">3.2.3.</span> <span class="nav-text">常用分布的方差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%B9%E5%B7%AE%E7%9A%84%E7%AE%80%E5%8D%95%E6%80%A7%E8%B4%A8"><span class="nav-number">3.2.4.</span> <span class="nav-text">方差的简单性质</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E4%B8%8D%E7%AD%89%E5%BC%8F"><span class="nav-number">3.2.5.</span> <span class="nav-text">切比雪夫不等式</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E9%9A%8F%E6%9C%BA%E5%90%91%E9%87%8F"><span class="nav-number">4.</span> <span class="nav-text">第四章 随机向量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%90%91%E9%87%8F%E7%9A%84%E8%81%94%E5%90%88%E5%88%86%E5%B8%83%E4%B8%8E%E8%BE%B9%E7%BC%98%E5%88%86%E5%B8%83"><span class="nav-number">4.1.</span> <span class="nav-text">二维随机向量的联合分布与边缘分布</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%90%91%E9%87%8F%E7%9A%84%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83"><span class="nav-number">4.1.1.</span> <span class="nav-text">离散型随机向量的概率分布</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%90%91%E9%87%8F%E7%9A%84%E8%BE%B9%E7%BC%98%E5%88%86%E5%B8%83%E4%B8%8E%E8%81%94%E5%90%88%E5%88%86%E5%B8%83"><span class="nav-number">4.1.2.</span> <span class="nav-text">离散型随机向量的边缘分布与联合分布</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9E%E7%BB%AD%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%90%91%E9%87%8F%E7%9A%84%E8%81%94%E5%90%88%E5%88%86%E5%B8%83"><span class="nav-number">4.1.3.</span> <span class="nav-text">连续型随机向量的联合分布</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9E%E7%BB%AD%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%90%91%E9%87%8F%E7%9A%84%E8%BE%B9%E7%BC%98%E5%88%86%E5%B8%83"><span class="nav-number">4.1.4.</span> <span class="nav-text">连续型随机向量的边缘分布</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E7%8B%AC%E7%AB%8B%E6%80%A7"><span class="nav-number">4.1.5.</span> <span class="nav-text">随机变量的独立性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83"><span class="nav-number">4.1.6.</span> <span class="nav-text">二维正态分布</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%90%91%E9%87%8F%E7%9A%84%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0"><span class="nav-number">4.1.7.</span> <span class="nav-text">二维随机向量的分布函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%A4%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%87%BD%E6%95%B0%E7%9A%84%E5%88%86%E5%B8%83"><span class="nav-number">4.2.</span> <span class="nav-text">两个随机变量的函数的分布</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%87%BD%E6%95%B0%E7%9A%84%E8%81%94%E5%90%88%E5%AF%86%E5%BA%A6"><span class="nav-number">4.2.1.</span> <span class="nav-text">随机变量函数的联合密度</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%90%91%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81"><span class="nav-number">4.3.</span> <span class="nav-text">随机向量的数字特征</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%A4%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%9D%87%E5%80%BC%E5%85%AC%E5%BC%8F"><span class="nav-number">4.3.1.</span> <span class="nav-text">两个随机变量的均值公式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%A4%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%90%91%E9%87%8F%E5%9D%87%E5%80%BC%E5%92%8C%E6%96%B9%E5%B7%AE%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="nav-number">4.3.2.</span> <span class="nav-text">两个随机向量均值和方差的性质</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%A4%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%92%8C%E7%9A%84%E5%9D%87%E5%80%BC%E4%B8%8E%E6%96%B9%E5%B7%AE"><span class="nav-number">4.3.3.</span> <span class="nav-text">两个随机变量的和的均值与方差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%90%91%E9%87%8F%E7%9A%84%E5%9D%87%E5%80%BC%E5%92%8C%E5%8D%8F%E6%96%B9%E5%B7%AE"><span class="nav-number">4.3.4.</span> <span class="nav-text">随机向量的均值和协方差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%90%91%E9%87%8F%E7%9A%84%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0"><span class="nav-number">4.3.5.</span> <span class="nav-text">随机向量的相关系数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%90%91%E9%87%8F"><span class="nav-number">4.4.</span> <span class="nav-text">多维随机向量</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%94%E5%90%88%E5%AF%86%E5%BA%A6%E4%B8%8E%E8%BE%B9%E7%BC%98%E5%AF%86%E5%BA%A6"><span class="nav-number">4.4.1.</span> <span class="nav-text">联合密度与边缘密度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%8B%AC%E7%AB%8B%E6%80%A7"><span class="nav-number">4.4.2.</span> <span class="nav-text">独立性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#n-%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%87%BD%E6%95%B0%E7%9A%84%E5%88%86%E5%B8%83"><span class="nav-number">4.4.3.</span> <span class="nav-text">$n$ 个随机变量的函数的分布</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81"><span class="nav-number">4.4.4.</span> <span class="nav-text">数字特征</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9D%87%E5%80%BC%E5%85%AC%E5%BC%8F"><span class="nav-number">4.4.4.1.</span> <span class="nav-text">均值公式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9D%87%E5%80%BC%E4%B8%8E%E6%96%B9%E5%B7%AE%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="nav-number">4.4.4.2.</span> <span class="nav-text">均值与方差的性质</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8D%8F%E6%96%B9%E5%B7%AE%E4%B8%8E%E5%8D%8F%E5%B7%AE%E9%98%B5"><span class="nav-number">4.4.4.3.</span> <span class="nav-text">协方差与协差阵</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E4%B8%8E%E7%9B%B8%E5%85%B3%E9%98%B5"><span class="nav-number">4.4.4.4.</span> <span class="nav-text">相关系数与相关阵</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#n-%E7%BB%B4%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0"><span class="nav-number">4.4.4.5.</span> <span class="nav-text">$n$ 维分布函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E5%92%8C%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86"><span class="nav-number">4.5.</span> <span class="nav-text">大数定律和中心极限定理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B"><span class="nav-number">4.5.1.</span> <span class="nav-text">大数定律</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%BA%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B"><span class="nav-number">4.5.2.</span> <span class="nav-text">强大数定律</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86"><span class="nav-number">4.5.3.</span> <span class="nav-text">中心极限定理</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%BB%9F%E8%AE%A1%E4%BC%B0%E5%80%BC"><span class="nav-number">5.</span> <span class="nav-text">第五章 统计估值</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E4%BD%93%E4%B8%8E%E6%A0%B7%E6%9C%AC"><span class="nav-number">5.1.</span> <span class="nav-text">总体与样本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0%E4%B8%8E%E5%88%86%E5%B8%83%E5%AF%86%E5%BA%A6%E7%9A%84%E4%BC%B0%E8%AE%A1"><span class="nav-number">5.2.</span> <span class="nav-text">分布函数与分布密度的估计</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%8F%E9%AA%8C%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0"><span class="nav-number">5.2.1.</span> <span class="nav-text">经验分布函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%8F%E9%AA%8C%E5%88%86%E5%B8%83%E5%AF%86%E5%BA%A6"><span class="nav-number">5.2.2.</span> <span class="nav-text">经验分布密度</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E7%9B%B4%E6%96%B9%E5%9B%BE%E6%B3%95"><span class="nav-number">5.2.2.1.</span> <span class="nav-text">(1) 直方图法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-%E6%A0%B8%E4%BC%B0%E8%AE%A1%E6%B3%95"><span class="nav-number">5.2.2.2.</span> <span class="nav-text">(2) 核估计法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-%E6%9C%80%E8%BF%91%E9%82%BB%E4%BC%B0%E8%AE%A1%E6%B3%95"><span class="nav-number">5.2.2.3.</span> <span class="nav-text">(3) 最近邻估计法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="nav-number">5.3.</span> <span class="nav-text">最大似然估计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%9F%E6%9C%9B%E5%92%8C%E6%96%B9%E5%B7%AE%E7%9A%84%E7%82%B9%E4%BC%B0%E8%AE%A1"><span class="nav-number">5.4.</span> <span class="nav-text">期望和方差的点估计</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%9F%E6%9C%9B%E7%9A%84%E7%82%B9%E4%BC%B0%E8%AE%A1"><span class="nav-number">5.4.1.</span> <span class="nav-text">期望的点估计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%B9%E5%B7%AE%E7%9A%84%E7%82%B9%E4%BC%B0%E8%AE%A1"><span class="nav-number">5.4.2.</span> <span class="nav-text">方差的点估计</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%9F%E6%9C%9B%E7%9A%84%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4"><span class="nav-number">5.5.</span> <span class="nav-text">期望的置信区间</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B7%B2%E7%9F%A5%E6%96%B9%E5%B7%AE%EF%BC%8C%E5%AF%B9%E6%9C%9F%E6%9C%9B%E8%BF%9B%E8%A1%8C%E5%8C%BA%E9%97%B4%E4%BC%B0%E8%AE%A1"><span class="nav-number">5.5.1.</span> <span class="nav-text">已知方差，对期望进行区间估计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%AA%E7%9F%A5%E6%96%B9%E5%B7%AE%EF%BC%8C%E5%AF%B9%E6%9C%9F%E6%9C%9B%E8%BF%9B%E8%A1%8C%E5%8C%BA%E9%97%B4%E4%BC%B0%E8%AE%A1"><span class="nav-number">5.5.2.</span> <span class="nav-text">未知方差，对期望进行区间估计</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E5%B7%AE%E7%9A%84%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4"><span class="nav-number">5.6.</span> <span class="nav-text">方差的置信区间</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E5%85%AD%E7%AB%A0-%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C"><span class="nav-number">6.</span> <span class="nav-text">第六章 假设检验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%E7%9A%84%E6%8F%90%E6%B3%95"><span class="nav-number">6.1.</span> <span class="nav-text">问题的提法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E4%B8%AA%E6%AD%A3%E6%80%81%E6%80%BB%E4%BD%93%E7%9A%84%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C"><span class="nav-number">6.2.</span> <span class="nav-text">一个正态总体的假设检验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%B7%B2%E7%9F%A5%E6%96%B9%E5%B7%AE%EF%BC%8C%E6%A3%80%E9%AA%8C%E6%9C%9F%E6%9C%9B"><span class="nav-number">6.2.1.</span> <span class="nav-text">1. 已知方差，检验期望</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E6%9C%AA%E7%9F%A5%E6%96%B9%E5%B7%AE%EF%BC%8C%E6%A3%80%E9%AA%8C%E6%9C%9F%E6%9C%9B"><span class="nav-number">6.2.2.</span> <span class="nav-text">2. 未知方差，检验期望</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E6%9C%AA%E7%9F%A5%E6%9C%9F%E6%9C%9B%EF%BC%8C%E6%A3%80%E9%AA%8C%E6%96%B9%E5%B7%AE"><span class="nav-number">6.2.3.</span> <span class="nav-text">3. 未知期望，检验方差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E6%9C%AA%E7%9F%A5%E6%9C%9F%E6%9C%9B%EF%BC%8C%E6%A3%80%E9%AA%8C%E6%96%B9%E5%B7%AE%E7%9A%84%E4%B8%8A%E9%99%90"><span class="nav-number">6.2.4.</span> <span class="nav-text">4. 未知期望，检验方差的上限</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%A4%E4%B8%AA%E6%AD%A3%E6%80%81%E6%80%BB%E4%BD%93%E7%9A%84%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C"><span class="nav-number">6.3.</span> <span class="nav-text">两个正态总体的假设检验</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%B8%83%E7%AB%A0-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90"><span class="nav-number">7.</span> <span class="nav-text">第七章 回归分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">7.1.</span> <span class="nav-text">一元线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%8F%E9%AA%8C%E5%85%AC%E5%BC%8F%E4%B8%8E%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95"><span class="nav-number">7.1.1.</span> <span class="nav-text">经验公式与最小二乘法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BD%93%E7%9B%B8%E5%85%B3%E5%85%B3%E7%B3%BB%E4%B8%8D%E6%98%AF%E7%BA%BF%E6%80%A7%E5%85%B3%E7%B3%BB%E6%97%B6%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%EF%BC%9F"><span class="nav-number">7.1.1.1.</span> <span class="nav-text">当相关关系不是线性关系时如何使用最小二乘法？</span></a></li></ol></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Henry"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Henry</p>
  <div class="site-description" itemprop="description">吾日三省吾身</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">17</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/hzhu212" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hzhu212" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhuhe212@163.com" title="E-Mail → mailto:zhuhe212@163.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/he-zhu-76-25/activities" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;he-zhu-76-25&#x2F;activities" rel="noopener me" target="_blank"><i class="fa fa-globe fa-fw"></i>知乎</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.jianshu.com/u/4e3f3cc93322" title="简书 → https:&#x2F;&#x2F;www.jianshu.com&#x2F;u&#x2F;4e3f3cc93322" rel="noopener me" target="_blank"><i class="fa fa-globe fa-fw"></i>简书</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hzhu212.github.io/posts/b59aba05/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Henry">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Henry's Blog">
      <meta itemprop="description" content="吾日三省吾身">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="概率统计笔记 | Henry's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          概率统计笔记
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-06-15 19:00:49" itemprop="dateCreated datePublished" datetime="2019-06-15T19:00:49+08:00">2019-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-04-07 14:10:19" itemprop="dateModified" datetime="2025-04-07T14:10:19+08:00">2025-04-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
        </span>
    </span>

  
    <span id="/posts/b59aba05/" class="post-meta-item leancloud_visitors" data-flag-title="概率统计笔记" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>本文为 <a target="_blank" rel="noopener" href="https://book.douban.com/subject/1748397/">概率统计讲义</a> 一书的笔记。</p>
<span id="more"></span>
<h2 id="第一章-随机事件与概率">第一章 随机事件与概率</h2>
<h3 id="频率">频率</h3>
<p>$$ 频率=\frac{频数}{试验次数} $$</p>
<h3 id="概率">概率</h3>
<p><strong>定义</strong>：频率具有稳定性的事件叫作随机事件，频率的稳定值叫作该随机事件的概率。</p>
<p>随机事件 $A$ 在条件 $S$ 下发生的概率为 $p$，记作：</p>
<p>$$ P(A)=p $$</p>
<h4 id="等概完备事件组">等概完备事件组</h4>
<p><strong>定义</strong>：称一个事件组 $A_1, A_2, A_3, \cdots, A_n$ 为一个<strong>等概完备事件组</strong>，如果它具有下列三条性质：</p>
<ol>
<li><strong>等可能性</strong>：$A_1, A_2, A_3, \cdots, A_n$ 发生的机会相同</li>
<li><strong>完备性</strong>：在人一次试验中，$A_1, A_2, A_3, \cdots, A_n$ 至少有一个发生（也就是所谓的“除此之外，不可能有别的结果”）</li>
<li><strong>互不相容性</strong>：在任一次试验中，$A_1, A_2, A_3, \cdots, A_n$ 至多有一个发生（也就是所谓“他们是互相排斥的”）</li>
</ol>
<p>等概完备事件组又称等概基本事件组，其中的任意事件 $A_i(i=1,2,\cdots,n)$ 称为<strong>基本事件</strong>。</p>
<p>对于只满足条件 2、3 的事件组，称为<strong>完备事件组</strong>。</p>
<h4 id="事件的运算">事件的运算</h4>
<ol>
<li>
<p>必然事件表示为 $U$，不可能事件表示为 $V$。</p>
</li>
<li>
<p>包含：如果事件 $A$ 发生，那么 $B$ 必发生，就称事件 $B$ 包含事件 $A$，记作<br>
$$ A \subset B $$</p>
</li>
<li>
<p>相等：如果事件 $A$ 包含事件 $B$，同时事件 $B$ 包含事件 $A$，那么就称事件 $A$ 与 $B$ 相等或等价，记作<br>
$$ A=B $$</p>
</li>
<li>
<p>并：事件“$A$ 或 $B$”称为事件 $A$ 与事件 $B$ 的并，记作<br>
$$ A \cup B \quad 或 \quad A+B $$</p>
</li>
<li>
<p>交：事件“$A$ 且 $B$”称为事件 $A$ 和事件 $B$ 的交，记作<br>
$$ A \cap B \quad 或 \quad AB \quad 或 \quad A \cdot B $$</p>
</li>
<li>
<p>对立事件：事件“非$A$”称为 $A$ 的对立事件，记作 $\overline{A}$，有<br>
$$ A \cap \overline{A} = V $$<br>
$$ A \cup \overline{A} = U $$</p>
</li>
<li>
<p>事件的差：事件 $A$ 同 $B$ 的差表示 $A$ 发生而 $B$ 不发生的事件，记作 $A \backslash B$，由定义可知<br>
$$ A \backslash B = A \cap \overline{B} $$</p>
</li>
</ol>
<h4 id="事件的互不相容性">事件的互不相容性</h4>
<p>如果事件 $A$ 与事件 $B$ 不能同时发生，即：</p>
<p>$$ AB = V(不可能事件) $$</p>
<p>那么，称 $A$ 与 $B$ 是互不相容事件。</p>
<h4 id="概率的加法公式">概率的加法公式</h4>
<p>如果事件 $A$，$B$ 互不相容，则</p>
<p>$$ P(A \cup B) = P(A) + P(B) $$</p>
<h4 id="条件概率">条件概率</h4>
<p>如果 $A$，$B$ 是条件 $S$ 下的两个随机事件，$P(A) \neq 0$，则称在 $A$ 发生的前提下 $B$ 发生的概率为<strong>条件概率</strong>，记作 $P(B \mid A)$</p>
<h4 id="概率的乘法公式">概率的乘法公式</h4>
<p>$$ P(AB) = P(A) P(B \mid A) $$</p>
<p>进一步有</p>
<p>$$ P(A) P(B \mid A) = P(B) P(A \mid B) $$</p>
<h4 id="事件的独立性">事件的独立性</h4>
<p>事件 $A$ 的发生并不影响事件 $B$ 的发生，即：</p>
<p>$$ P(B \mid A) = P(B) $$</p>
<p>称两个事件 $A$，$B$ 是<strong>相互独立</strong>的。此时有：</p>
<p>$$ P(AB) = P(A) P(B) $$</p>
<h4 id="全概公式">全概公式</h4>
<p>设事件组 $A_1, A_2, A_3, \cdots, A_n$ 为完备事件组，则对任意一个事件 $B$ 有：</p>
<p>$$ P(B) = \sum_{i=1}^{n} P(B \mid A_i) P(A_i) $$</p>
<p>考虑 $n=2$ 时的简化情况，有：</p>
<p>$$ P(B) = P(B \mid A) P(A) + P(B \mid \overline{A}) P(\overline{A}) $$</p>
<h4 id="逆概公式">逆概公式</h4>
<p>设事件组 $A_1, A_2, A_3, \cdots, A_n$ 为完备事件组，则对任意一个事件 $B$ 有：</p>
<p>$$ P(A_j \mid B) = \frac{P(B \mid A_j) P(A_j)}{\sum_{i=1}^{n} P(B \mid A_i) P(A_i)} \; (j=1,\cdots,n) $$</p>
<p>逆概公式也称为<strong>贝叶斯公式</strong>，本质上是乘法公式与全概公式的结合，即：</p>
<p>$$ P(A_j \mid B) = \frac{P(A_j B)}{P(B)} = \frac{P(B \mid A_j) P(A_j)}{\sum_{i=1}^{n} P(B \mid A_i) P(A_i)} \; (j=1,\cdots,n) $$</p>
<h4 id="独立试验序列概型">独立试验序列概型</h4>
<p>设每次射击打中目标的概率为 $p$，连续射击 $n$ 次，求恰好打中 $k$ 次的概率。</p>
<p>设单次试验中，事件 $A$ 发生的概率为 $p(0 \lt p \lt 1)$，则在 $n$ 次重复实验中：</p>
<p>$$ P(A发生k次) = C_n^k p^k q^{n-k} \quad (q=1-p; k=0,1,2,\cdots,n) $$</p>
<h2 id="第二章-随机变量与概率分布">第二章 随机变量与概率分布</h2>
<h3 id="随机变量">随机变量</h3>
<p><strong>定义</strong>：对于条件组 $S$ 下的每一个可能结果 $\omega$ 都唯一的对应到一个实数值 $X(\omega)$，则称实值变量 $X(\omega)$ 为一个随机变量，简记为 $X$。</p>
<p>举个例子：设盒中有 5 个球，其中 2 个白球、3 个黑球，从中随便取 3 个球。则“抽得的白球数”$X$ 是一个随机变量。</p>
<p>随机变量分为<strong>离散型随机变量</strong>和<strong>连续型随机变量</strong>。</p>
<h3 id="一、离散型随机变量">一、离散型随机变量</h3>
<p>将随机变量 $X$ 的所有可能取值到其相应概率的映射称为 $X$ 的概率分布，记为：</p>
<p>$$ p_k = P\{X=x_k\} \quad (k=1,2,\cdots) $$</p>
<h4 id="常用的离散型随机变量的概率分布">常用的离散型随机变量的概率分布</h4>
<ol>
<li>
<p>两点分布<br>
随机变量 $X$ 仅取两个值：0 或 1，即</p>
<p>$$ \begin{aligned}<br>
&amp; P\{X=1\}=p \quad (0 \lt p \lt 1) \\<br>
&amp; P\{X=0\}=q \quad (q=1-p)<br>
\end{aligned} $$</p>
</li>
<li>
<p>二项分布<br>
$$ P\{X=k\} = C_n^k p^k q^{n-k} \quad (k=0,1,2,\cdots,n;\; 0 \lt p \lt 1;\;q=1-p) $$</p>
<p>随机变量 $X$ 满足二项分布可简记为：$X \sim B(n,p)$</p>
</li>
<li>
<p>泊松分布<br>
$$ P\{X=k\} = \frac{\lambda^k}{k!} e^{-\lambda} \quad (k=0,1,2,\cdots,n) $$</p>
<p>当 $\displaystyle \lim_{n \to \infty} np = \lambda$ 时，泊松分布等同于二项分布。</p>
</li>
<li>
<p>超几何分布<br>
$$ P\{X=m\} = \frac{C_M^m C_{N-M}^{n-m}}{C_N^n} \quad (m=0,1,2,\cdots,l;\; 其中 l=\min(M,n)) $$</p>
<p>示例：设一堆同类产品共 $N$ 个，其中有 $M$ 个次品。现从中任取 $n$ 个（假定 $n \le N-M$），则这 $n$ 个样品中所含次品个数 $X$ 是一个离散型随机变量，其概率分布为超几何分布。</p>
</li>
</ol>
<h3 id="二、连续型随机变量">二、连续型随机变量</h3>
<h4 id="概率密度函数">概率密度函数</h4>
<p><strong>定义</strong>：对于随机变量 $X$，如果存在非负可积函数 $p(x)(-\infty \lt x \lt \infty)$，使对任意的 $a,b(a \lt b)$ 都有：</p>
<p>$$ P\{a \lt X \lt b\} = \int_a^b p(x) \mathrm{d}x $$</p>
<p>则称 $X$ 为<strong>连续性随机变量</strong>；称 $p(x)$ 为 $X$ 的<strong>概率密度函数</strong>，简称概率密度或密度。</p>
<p>与离散型随机变量类比：将离散型随机变量 $X$ 的离散值无限细分，则 $X$ 的概率分布将变为概率密度函数。</p>
<p>显然，概率密度函数满足以下两条性质：</p>
<ol>
<li>
<p>对任何实数 $a$，有<br>
$$ P\{X=a\} = 0 $$</p>
</li>
<li>
<p>概率密度在整个实数轴上的积分为 1<br>
$$ \int_{-\infty}^{\infty} p(x) \mathrm{d}x = 1 $$</p>
</li>
</ol>
<h4 id="常见概率密度函数">常见概率密度函数</h4>
<ol>
<li>
<p>均匀分布<br>
如果随机变量 $X$ 的概率密度为</p>
<p>$$ p(x) = \begin{cases}<br>
\lambda \qquad 当 a \le x \le b \\<br>
0 \qquad 其他 \end{cases} \quad (a \lt b) $$</p>
<p>则称 $X$ 服从 $[a,b]$ 区间上的均匀分布</p>
</li>
<li>
<p>指数分布</p>
<p>$$ p(x) = \begin{cases}<br>
\lambda e^{-\lambda x} &amp; 当 x \ge 0 \\<br>
0 &amp; 当 x \lt 0 \end{cases} \quad (\lambda \gt 0) $$</p>
</li>
<li>
<p>正态分布</p>
<p>$$ p(x) = \frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{1}{2 \sigma^2}(x-\mu)^2} \quad (-\infty \lt x \lt \infty,\;\sigma \gt 0) $$</p>
<p>变量 $X$ 服从正态分布 $N(\mu,\sigma^2)$ 可简记为 $X \sim N(\mu,\sigma^2)$。</p>
<p><strong>标准正态分布</strong>：参数 $\mu=0, \sigma=1$ 时的正态分布，即 $N(0,1)$。它的密度函数为</p>
<p>$$ p(x) = \frac{1}{\sqrt{2 \pi}} e^{-\frac{x^2}{2}} $$</p>
<p><strong>一个重要的积分</strong>：</p>
<p>$$ \int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi}} e^{-\frac{x^2}{2}} \mathrm{d}x = 1 $$</p>
<p>通过正态分布的密度函数求某个区间的概率时，需要计算密度函数的积分，这种计算非常复杂，因此我们通过已经计算好数值的 $\Phi$ 函数来帮助求解：</p>
<p>$$ \Phi(x) = \int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} e^{-\frac{t^2}{2}} \mathrm{d}t $$</p>
<p>那么对于标准正态分布，有</p>
<p>$$ P\{a \lt X \lt b\} = \Phi(b) - \Phi(a) $$</p>
<p>对于一般正态分布 $N(\mu,\sigma^2)$，常常使用<strong>变量替换法</strong>将其转化为标准正态分布，即令</p>
<p>$$ t = \frac{x-\mu}{\sigma} $$</p>
<p>这时，$X \sim N(\mu,\sigma) \rightarrow T \sim N(0,1)$。这样，对于一般正态分布也能轻易地计算其积分了。</p>
</li>
<li>
<p>$\Gamma$ 分布</p>
<p>$$ p(x) = \begin{cases}<br>
\frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x} &amp; x \gt 0 \\<br>
0 &amp; x \le 0 \end{cases} \quad (\alpha \gt 0, \beta \gt 0) $$</p>
<p>其中</p>
<p>$$ \Gamma(\alpha) = \int_0^{\infty} x^{\alpha-1} e^{-x} \mathrm{d}x $$</p>
<p>变量 $X$ 服从 $\Gamma$ 分布可简记为 $X \sim \Gamma(\alpha, \beta)$</p>
</li>
<li>
<p>韦布尔分布</p>
<p>$$ p(x) = \begin{cases}<br>
m \frac{x^{m-1}}{\eta^m} e^{-(\frac{x}{\eta})^m} &amp; x \gt 0 \\<br>
0 &amp; x \le 0 \end{cases} $$</p>
</li>
</ol>
<h4 id="分布函数">分布函数</h4>
<p><strong>定义</strong>：设 $X$ 是一个随机变量（可以是连续型的，也可以是离散型的，甚至更一般的），称函数</p>
<p>$$ F(x) = P(X \le x) \quad (-\infty \lt x \lt +\infty) $$ 为 $X$ 的分布函数。</p>
<p>连续型随机变量的分布函数事实上是其概率密度函数在区间 $(-\infty, x]$ 上的不定上限积分。</p>
<h4 id="随机变量函数的分布">随机变量函数的分布</h4>
<p><strong>随机变量函数</strong>：随机变量 $X$ 的函数也是一个随机变量，记作</p>
<p>$$ Y = f(X) $$</p>
<p>满足当 $X$ 取值为 $x$ 时，$y$ 取值为 $f(x)$。</p>
<p>举个例子：设 $X$ 是分子的速率，而 $Y$ 是分子的动能，则 $Y$ 是 $X$ 的函数：$Y=\frac{1}{2}mX^2$（$m$ 为分子质量）。</p>
<p>我们的目的是，根据已知的 $X$ 的分布来寻求 $Y=f(X)$ 的分布。</p>
<h5 id="离散型随机变量函数的分布">离散型随机变量函数的分布</h5>
<p>假设离散型随机变量 $X, Y$ 有如下关系：$Y=f(X)$。要得到 $P\{Y=y_i\}$，只需求出 $Y=y_i$ 时对应的 $x_i$（可能有 0 个或多个对应值），将这些 $x_i$ 对应的概率相加即可。</p>
<h5 id="连续型随机变量函数的分布">连续型随机变量函数的分布</h5>
<p><strong>分布函数法</strong>：已知 $X$ 的分布，通过建立 $Y$ 与 $X$ 的分布函数之间的关系来求得 $Y$ 的分布。</p>
<p>举个例子：已知 $X \sim N(\mu,\sigma^2)$，求 $Y=\frac{X-\mu}{\sigma}$ 的概率密度。</p>
<p>解：设 $Y$ 的分布函数为 $F_Y(y)$，于是</p>
<p>$$ \begin{aligned}<br>
F_Y(y) &amp; = P(Y \le y) \quad (分布函数的定义) \\<br>
&amp; = P(\frac{X-\mu}{\sigma} \le y) \quad (Y=\frac{X-\mu}{\sigma}) \\<br>
&amp; = P(X \le \sigma y + \mu) \quad (不等式变形) \\<br>
&amp; = F_X(\sigma y + \mu) \quad (分布函数的定义)<br>
\end{aligned} $$</p>
<p>其中 $F_X(x)$ 为 $X$ 的分布函数。那么，我们有</p>
<p>$$ F_Y(y) = F_X(\sigma y + \mu) $$</p>
<p>将上式两边对 $y$ 求微分，利用<strong>密度函数是分布函数的导数</strong>的关系，我们得到</p>
<p>$$ p_Y(y) = p_X(\sigma y + \mu) \sigma $$</p>
<p>再将</p>
<p>$$ p_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{1}{2 \sigma^2}(x-\mu)^2} $$</p>
<p>代入，有</p>
<p>$$ p_Y(y) = \frac{1}{\sqrt{2 \pi}} e^{-\frac{y^2}{2}} $$</p>
<p>这表明 $Y \sim N(0,1)$。</p>
<h2 id="第三章-随机变量的数字特征">第三章 随机变量的数字特征</h2>
<h3 id="随机变量的期望">随机变量的期望</h3>
<p>随机变量的期望 $E(X)$ 是一个实数，它形式上是 $X$ 所有可能取值的加权平均，代表了随机变量 $X$ 的平均值。因此，也称期望为<strong>均值</strong>或<strong>分布的均值</strong>。</p>
<h4 id="离散型随机变量的期望">离散型随机变量的期望</h4>
<p>$$ E(X) = \sum_k x_k p_k \quad (=x_1p_1+x_2p_2+\cdots+x_kp_k+\cdots) $$</p>
<h5 id="几个常用分布的期望">几个常用分布的期望</h5>
<ol>
<li>
<p>两点分布<br>
$$ E(X) = 1 \cdot p + 0 \cdot q = p $$</p>
</li>
<li>
<p>二项分布<br>
$$ E(X) = \sum_{k=1}^n k C_n^k p^k q^{n-k} = np $$</p>
</li>
<li>
<p>泊松分布</p>
<p>$$ \begin{aligned}<br>
E(X) &amp; = \sum_{k=0}^\infty k \cdot \frac{\lambda^k}{k!} e^{-\lambda} \\<br>
&amp; = \lambda e^{-\lambda} \sum_{m=0}^\infty \frac{\lambda^m}{m!} \quad (令m=k-1) \\<br>
&amp; = \lambda e^{-\lambda} e^{\lambda} \quad (泊松分布的密度之和为 1) \\<br>
&amp; = \lambda<br>
\end{aligned} $$</p>
</li>
<li>
<p>超几何分布<br>
$$ E(X) = \frac{nM}{N} $$</p>
</li>
</ol>
<h4 id="连续型随机变量的期望">连续型随机变量的期望</h4>
<p><strong>定义</strong>：设连续型随机变量$X$的密度函数为 $p(x)$，称</p>
<p>$$ \int_{-\infty}^{+\infty} xp(x) \mathrm{d}x $$</p>
<p>为 $X$ 的<strong>期望</strong>（或均值），记作 $E(X)$。</p>
<p>本定义要求 $\displaystyle \int_{-\infty}^{+\infty} \vert x \vert p(x) \mathrm{d}x$ 收敛</p>
<h5 id="几个常用分布的期望-2">几个常用分布的期望</h5>
<ol>
<li>
<p>均匀分布<br>
$$ E(X) = \frac{1}{2}(b+a) $$</p>
</li>
<li>
<p>指数分布</p>
<p>$$ \begin{aligned}<br>
E(X) &amp; = \int_{-\infty}^{+\infty} xp(x) \mathrm{d}x \\<br>
&amp; = \int_{0}^{+\infty} \lambda x e^{-\lambda x} \mathrm{d}x \\<br>
&amp; = \frac{1}{\lambda} \int_0^{+\infty} te^{-t} \mathrm{d}t \quad (令t=\lambda x) \\<br>
&amp; = -\frac{1}{\lambda} \int_0^{+\infty} t \mathrm{d}e^{-t} \\<br>
&amp; = -\frac{1}{\lambda}\left[(te^{-t}) \Big|_0^{+\infty}-\int_0^{+\infty}e^{-t}\mathrm{d}t \right] \\<br>
&amp; = \frac{1}{\lambda}<br>
\end{aligned} $$</p>
</li>
<li>
<p>正态分布<br>
$$ E(X) = \mu $$</p>
<p>证明略。正态分布密度函数以 $x=\mu$ 为对称轴，这就是其含义所在。</p>
</li>
</ol>
<h4 id="期望的简单性质">期望的简单性质</h4>
<p>$$ \begin{aligned}<br>
E© &amp;= c \\<br>
E(kX) &amp;= kE(X) \\<br>
E(X+b) &amp;= E(X) + b \\<br>
E(kX+b) &amp;= kE(X) + b<br>
\end{aligned} $$</p>
<p>一言以蔽之，<strong>期望是线性的</strong>。</p>
<h4 id="随机变量函数的期望">随机变量函数的期望</h4>
<p>对于离散型随机变量有</p>
<p>$$ E\left[f(X)\right] = \sum_i f(x_i)p_i $$</p>
<p>对于连续型随机变量有</p>
<p>$$ E\left[f(X)\right] = \int_{-\infty}^{+\infty} f(x)p(x) \mathrm{d}x $$</p>
<p><strong>求随机变量函数的期望</strong>有如下两种方法：</p>
<ol>
<li>利用上述随机变量函数的期望公式直接求解；</li>
<li>首先通过 $X$ 的分布推出 $f(X)$ 的分布，然后通过期望的定义求出 $f(X)$ 的期望。</li>
</ol>
<p>一般来说，第一种方法较为简单，是我们的首选方法。</p>
<h3 id="随机变量的方差">随机变量的方差</h3>
<p><strong>定义</strong>：</p>
<p>$$ D(X) = E \left\{ [X-E(X)]^2 \right\} $$ 这表明 $X$ 的方差，就是随机变量 $[X-E(X)]^2$ 的期望。</p>
<blockquote>
<p>💡 定性认识，$D(X)$ 越小，则 $X$ 取值越集中在 $E(X)$ 附近。方差刻画了随机变量取值的分散程度。</p>
</blockquote>
<p><strong>方差简化计算公式</strong>：</p>
<p>$$ D(X) = E(X^2) - E^2(X) $$</p>
<p>推导如下：</p>
<p>$$ \begin{aligned}<br>
D(X) &amp;= \int_{-\infty}^{+\infty} \left[x-E(X) \right]^2 p(x) \mathrm{d}x \\<br>
&amp;= \int_{-\infty}^{+\infty} \left[x^2-2xE(X)+E^2(X) \right] p(x) \mathrm{d}x \\<br>
&amp;= \int_{-\infty}^{+\infty}x^2p(x)\mathrm{d}x - 2E(X)\int_{-\infty}^{+\infty}xp(x)\mathrm{d}x + E^2(X)\int_{-\infty}^{+\infty}p(x)\mathrm{d}x \\<br>
&amp;= E(X^2) - 2E(X)\cdot E(X) + E^2(X)\cdot 1 \\<br>
&amp;= E(X^2) - E^2(X)<br>
\end{aligned} $$</p>
<h4 id="离散型随机变量的方差">离散型随机变量的方差</h4>
<p><strong>定义</strong>：设离散型随机变量的概率分布为</p>
<p>$$ P(X=x_k) = P_k \quad (k=1,2,\cdots) $$</p>
<p>则称和数</p>
<p>$$ \sum_k \left[ x_k-E(X) \right]^2 p_k $$</p>
<p>为 $X$ 的方差，记作 $D(X)$。</p>
<h4 id="连续型随机变量的方差">连续型随机变量的方差</h4>
<p><strong>定义</strong>：设连续型随机变量的密度为 $p(x)$，则称</p>
<p>$$ \int_{-\infty}^{+\infty} \left[ x-E(X) \right]^2 p(x) \mathrm{d}x $$</p>
<p>为 $X$ 的方差，记作 $D(X)$。</p>
<h4 id="常用分布的方差">常用分布的方差</h4>
<ol>
<li>
<p>两点分布</p>
<p>$$ \begin{aligned}<br>
D(X) &amp;= E(X^2) - E^2(X) \\<br>
&amp;= (1^2 \cdot p + 0^2\cdot q) - p^2 \\<br>
&amp;= pq<br>
\end{aligned} $$</p>
</li>
<li>
<p>二项分布<br>
$$ D(X) = npq $$</p>
</li>
<li>
<p>泊松分布<br>
已知 $E(X)=\lambda$，</p>
<p>$$ \begin{aligned}<br>
E(X^2) &amp;= \sum_{k=0}^{\infty} K^2 \cdot \frac{\lambda^k}{k!} e^{-\lambda} \\<br>
&amp;= \sum_{k=1}^{\infty} (k-1+1) \frac{\lambda^k}{(k-1)!} e^{-\lambda} \\<br>
&amp;= \lambda^2 \cdot \sum_{k=2}^{\infty} \frac{\lambda^{k-2}}{(k-2)!}e^{-\lambda} + \lambda \cdot \sum_{k=1}^{\infty} \frac{\lambda^{k-1}}{(k-1)!}e^{-\lambda} \\<br>
&amp;= \lambda^2 + \lambda<br>
\end{aligned} $$</p>
<p>则</p>
<p>$$ D(X) = (\lambda^2 + \lambda) - \lambda^2 = \lambda $$</p>
</li>
<li>
<p>均匀分布<br>
$$ D(X) = \frac{1}{12}(b-a)^2 $$</p>
</li>
<li>
<p>指数分布<br>
$$ D(X) = \frac{1}{\lambda^2} $$</p>
</li>
<li>
<p>正态分布<br>
$$ D(X) = \sigma^2 $$</p>
</li>
</ol>
<h4 id="方差的简单性质">方差的简单性质</h4>
<p>$$ \begin{aligned}<br>
D© &amp;= 0 \\<br>
D(kX) &amp;= k^2 D(X) \\<br>
D(X+b) &amp;= D(X) \\<br>
D(kX+b) &amp;= k^2 D(X)<br>
\end{aligned} $$</p>
<h4 id="切比雪夫不等式">切比雪夫不等式</h4>
<p>$$ P\{ \vert X-E(X) \vert \ge \varepsilon \} \le \frac{D(X)}{\varepsilon^2} $$</p>
<h2 id="第四章-随机向量">第四章 随机向量</h2>
<p><strong>定义</strong>：我们称 $n$ 个随机变量 $X_1,X_2,\cdots,X_n$ 的整体 $\xi = (X_1,X_2,\cdots,X_n)$ 为 $n$ 维随机向量。</p>
<p>我们重点研究二维随机向量。</p>
<h3 id="二维随机向量的联合分布与边缘分布">二维随机向量的联合分布与边缘分布</h3>
<h4 id="离散型随机向量的概率分布">离散型随机向量的概率分布</h4>
<p>$\xi = (X,Y)$ 为二维离散型随机向量，当且仅当 $X,Y$ 都是离散型随机变量。</p>
<p>一般称</p>
<p>$$ P\{(X,Y)=(x_i,y_j)\} = p_{ij} \quad (i=1,2,\cdots ;j=1,2,\cdots) $$</p>
<p>为 $\xi=(X,Y)$ 的概率分布，也称为 $(X,Y)$ 的<strong>联合分布</strong>。常采用<strong>概率分布表</strong>来表示离散型随机向量的概率分布。这些 $p_{ij}$ 具有 2 条基本性质：</p>
<ol>
<li>
<p>非负：<br>
$$ p_{ij} \ge 0 $$</p>
</li>
<li>
<p>概率总和为 1：<br>
$$ \sum_i \sum_j p_{ij} = 1 $$</p>
</li>
</ol>
<p><strong>三项分布</strong>：</p>
<p>$$ P\{(X,Y)=(k_1,k_2)\} = \frac{n!}{k_1!k_2!(n-k_1-k_2)!}p_1^{k_1}p_2^{k_2}(1-p_1-p_2)^{n-k_1-k_2} $$</p>
<h4 id="离散型随机向量的边缘分布与联合分布">离散型随机向量的边缘分布与联合分布</h4>
<p><strong>边缘分布</strong>：对于二维随机向量 $(X,Y)$，分量 $X$ 的概率分布称为 $(X,Y)$ 的关于 $X$ 的边缘分布。</p>
<p>$$ P\{ X=x_i \} = \sum_j p_{ij} $$ $$ P\{ Y=y_j \} = \sum_i p_{ij} $$</p>
<p>如果将 $(X,Y)$ 的概率分布写在概率分布表中（$i$ 为行数，$j$ 为列数），则关于 $X$ 的边缘分布为“将每行加和得到的一列”；关于 $Y$ 的边缘分布为“将每列加和得到的一行”。</p>
<h4 id="连续型随机向量的联合分布">连续型随机向量的联合分布</h4>
<p><strong>概念</strong>：对于二维随机向量 $\xi=(X,Y)$，如果存在非负函数 $p(x,y)\;(x,y \in \mathbb{R})$，使对于任意一个邻边分别平行于坐标轴的矩形区域 $D$（即由不等式 $a\lt x\lt b,c\lt y\lt d$ 确定的区域），有</p>
<p>$$ P\{ (X,Y) \in D \} = \iint\limits_{D} p(x,y)\mathrm{d}x\mathrm{d}y $$</p>
<p>则称随机向量 $\xi=(X,Y)$ 为<strong>连续型</strong>的，并称 $p(x,y)$ 为 $\xi$ 的<strong>分布密度</strong>，也称 $p(x,y)$ 为 $(X,Y)$ 的<strong>联合分布密度</strong>。</p>
<p>由定义式容易得到</p>
<p>$$ \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}p(x,y)\mathrm{d}x\mathrm{d}y = 1 $$</p>
<blockquote>
<p>💡 二维随机向量 $(X,Y)$ 落在平面上任意区域 $D$ 的概率，就等于联合密度 $p(x,y)$ 在 $D$ 上的积分，这就把概率的计算转化为一个二重积分的计算。<br>
💡 几何意义：$\{(X,Y)\in D\}$ 的概率，数值上就等于以曲面 $z=p(x,y)$ 为顶、以平面区域 $D$ 为底的曲顶柱体的体积。</p>
</blockquote>
<h4 id="连续型随机向量的边缘分布">连续型随机向量的边缘分布</h4>
<p><strong>定义</strong>：对于随机向量 $(X,Y)$，作为其分量的随机变量 $X$（或 $Y$）的密度函数 $p_X(x)$（或 $p_Y(y)$），称为 $(X,Y)$ 的关于 $X$（或 $Y$）的<strong>边缘分布密度</strong>。</p>
<p>当 $(X,Y)$ 的联合密度 $p(x,y)$ 已知时，可通过以下方法求得边缘密度</p>
<p>$$ \begin{aligned}<br>
p_X(x) &amp;= \int_{-\infty}^{+\infty}p(x,y)\mathrm{d}y \\<br>
p_Y(y) &amp;= \int_{-\infty}^{+\infty}p(x,y)\mathrm{d}x<br>
\end{aligned} $$</p>
<h4 id="随机变量的独立性">随机变量的独立性</h4>
<p><strong>定义</strong>：设 $X,Y$ 是两个随机变量，如果对任意的 $a\lt b,c\lt d$，事件 $\{a\lt X\lt b\}$ 与 $\{c\lt Y\lt d\}$ 相互独立，则称 $X$ 与 $Y$ 是<strong>相互独立</strong>的。</p>
<p><strong>重要定理</strong>：设 $X,Y$ 分别有分布密度 $p_X(x),p_Y(y)$，则 $X$ 与 $Y$ 相互独立的<strong>充要条件</strong>是：二元函数</p>
<p>$$ p_X(x)p_Y(y) $$</p>
<p>是随机向量 $(X,Y)$ 的联合密度。</p>
<h4 id="二维正态分布">二维正态分布</h4>
<p>$$ p(x,y) = \frac{1}{2\pi \sigma_1\sigma_2\sqrt{1-\rho^2}}e^{-\frac{1}{2(1-\rho^2)}\left[\left(\frac{x-\mu_1}{\sigma_1}\right)^2 - \frac{2\rho(x-\mu_1)(y-\mu_2)}{\sigma_1\sigma_2} + \left(\frac{y-\mu_2}{\sigma_2}\right)^2\right]} $$</p>
<p>两个边缘密度分别是两个一维正态分布：</p>
<p>$$ \begin{aligned}<br>
P_X(x)=\frac{1}{\sqrt{2\pi}\sigma_1}e^{-\frac{(x-\mu_1)^2}{2\sigma_1^2}} \\<br>
P_Y(y)=\frac{1}{\sqrt{2\pi}\sigma_2}e^{-\frac{(y-\mu_2)^2}{2\sigma_2^2}}<br>
\end{aligned} $$</p>
<p>对于二维正态分布，<strong>两个分量 $X$ 与 $Y$ 独立</strong>的充要条件是 $\rho=0$。</p>
<h4 id="二维随机向量的分布函数">二维随机向量的分布函数</h4>
<p><strong>定义</strong>：设 $\xi=(X,Y)$ 是二维随机向量，称函数</p>
<p>$$ F(x,y) = P\{ X \le x, Y \le y \} $$</p>
<p>为它的<strong>分布函数</strong>。</p>
<p>若 $\xi=(X,Y)$ 的分布函数有二阶连续偏微商，则</p>
<p>$$ \frac{\partial^2 F(x,y)}{\partial x \partial y} $$</p>
<p>就是 $\xi$ 的<strong>分布密度</strong>。</p>
<h3 id="两个随机变量的函数的分布">两个随机变量的函数的分布</h3>
<table>
<thead>
<tr>
<th>问题</th>
<th>描述</th>
<th>求解</th>
</tr>
</thead>
<tbody>
<tr>
<td>1 个随机变量的函数的分布</td>
<td>已知 $X$ 的分布，求 $X$ 的函数 $Y=f(X)$ 的分布</td>
<td><strong>分布函数法</strong></td>
</tr>
<tr>
<td>2 个随机变量的函数的分布</td>
<td>已知 $(X,Y)$ 的联合密度，求 $Z=(X,Y)$ 的密度函数</td>
<td><strong>分布函数法</strong></td>
</tr>
</tbody>
</table>
<p>对于两个随机变量的函数的分布，我们同样采用<strong>分布函数法</strong>求解，包括如下 2 步：</p>
<ol>
<li>
<p>为求随机变量 $f(X,Y)$ 的密度，先求它的分布，即<br>
$$ P\{f(X,Y) \le z\} $$</p>
</li>
<li>
<p>在求 $P\{f(X,Y) \le z\}$ 的过程中，用到下列等式<br>
$$ P\{f(X,Y) \le z\} = \iint\limits_{f(X,Y)\le z} p(x,y) \mathrm{d}x\mathrm{d}y $$</p>
</li>
</ol>
<p>举个例子：设 $X,Y$ 相互独立且服从相同的分布 $N(0,1)$，求 $\sqrt{X^2+Y^2}$ 的密度。</p>
<p><strong>解</strong>：$(X,Y)$ 的联合密度为</p>
<p>$$ \begin{aligned}<br>
p(x,y) &amp;= \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}} \cdot \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}} \\<br>
&amp;= \frac{1}{2\pi} e^{-\frac{x^2+y^2}{2}}<br>
\end{aligned} $$</p>
<p>记 $Z=\sqrt{X^2+Y^2}$ 的分布函数为 $F_Z(z)$，则</p>
<p>$$ \begin{aligned}<br>
F_Z(x) &amp;= P\{Z \le z\} \\<br>
&amp;= P\{\sqrt{X^2+Y^2} \le z\} \\<br>
&amp;= \iint\limits_{\sqrt{x^2+y^2} \le z} p(x,y) \mathrm{d}x\mathrm{d}y \\<br>
&amp;= \iint\limits_{\sqrt{x^2+y^2} \le z} \frac{1}{2\pi} e^{-\frac{x^2+y^2}{2}} \mathrm{d}x\mathrm{d}y \\<br>
&amp;= \int_0^{2\pi} \mathrm{d}\theta \int_0^z \frac{1}{2\pi} e^{-\frac{1}{2}r^2}r \mathrm{d}r \quad (极坐标变换: x=r\cos\theta,y=r\sin\theta) \\<br>
&amp;= \int_0^z r e^{-\frac{1}{2} r^2} \mathrm{d}r<br>
\end{aligned} $$</p>
<p>当 $z\le 0$ 时 $F_Z(z)=0$。于是 $Z$ 的密度 $p(z)$ 为</p>
<p>$$ p(z) = \begin{cases}<br>
z e^{-\frac{1}{2} z^2} &amp; z \gt 0 \\<br>
0 &amp; z \le 0<br>
\end{cases} $$</p>
<p>这就是所谓的<strong>瑞利(Rayleigh)分布</strong>。</p>
<h4 id="随机变量函数的联合密度">随机变量函数的联合密度</h4>
<p><strong>问题描述</strong>：已知 $(X,Y)$ 的联合密度为 $p(x,y)$，而</p>
<p>$$ \begin{cases}<br>
u = f(x,y) \\<br>
v = g(x,y)<br>
\end{cases} $$</p>
<p>如何求出 $(U,V)$ 的联合密度？</p>
<p><strong>step1</strong>：假设 $(X,Y)$ 的联合密度 $p(x,y)$ 所在的平面区域为 $A$（可以是全平面），即 $P\{(X,Y)\in A\}=1$，我们可以得到 $(U,V)$ 的联合密度所在的区域 $G$：</p>
<p>$$ G = \{ (u,v) \mid u=f(x,y),v=g(x,y),(x,y)\in A \} $$</p>
<p><strong>step2</strong>： 根据 $u=f(x,y),v=g(x,y)$ 我们用 $u,v$表示出 $x,y$：</p>
<p>$$ x = x(u,v), \; y = y(u,v) $$</p>
<p><strong>step3</strong>：$(U,V)$ 的联合密度如下：</p>
<p>$$ q(u,v) = \begin{cases}<br>
p\left[ x(u,v),y(u,v) \right] \left| \frac{\partial(x,y)}{\partial(u,v)} \right| &amp; 当(u,v) \in G \\<br>
0 &amp; 当(u,v) \not\in G<br>
\end{cases} $$</p>
<p>其中，$\left| \frac{\partial(x,y)}{\partial(u,v)} \right|$ 是函数 $x(u,v),y(u,v)$ 的雅可比行列式的<strong>绝对值</strong>。</p>
<p>举个例子：设 $X,Y$ 相互独立，都服从 $N(0,1)$，</p>
<p>$$ \begin{aligned}<br>
X &amp;= R \cos \Theta \\<br>
Y &amp;= R \sin \Theta<br>
\end{aligned}<br>
\left( R \ge 0, \; 0 \le \Theta \le 2\pi \right) $$</p>
<p>求 $(R,\Theta)$ 的联合密度与边缘密度。</p>
<p><strong>解</strong>：由于 $X,Y$ 相互独立，则</p>
<p>$$ p(x,y) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}} \cdot \frac{1}{\sqrt{2\pi}} e^{-\frac{y^2}{2}} = \frac{1}{2\pi} e^{-\frac{x^2+y^2}{2}} $$</p>
<p>雅可比行列式</p>
<p>$$ J = \left| \frac{\partial(x,y)}{\partial(r,\theta)} \right| = \left| \begin{array}{cc} \cos\theta &amp; -r\sin\theta \\ \sin\theta &amp; r\cos\theta \end{array} \right| = r $$</p>
<p>则 $(R,\Theta)$ 的联合密度为</p>
<p>$$ q(r,\theta) = \begin{cases}<br>
\frac{1}{2\pi} r e^{-\frac{r^2}{2}} &amp; r \gt 0,\; 0 \lt \theta \lt 2\pi \\<br>
0 &amp; 其他<br>
\end{cases} $$</p>
<p>当 $r \gt 0$ 时，$R$ 的边缘密度为</p>
<p>$$ f® = \int_0^{2\pi} q(r,\theta) \mathrm{d}\theta = r e^{-\frac{r^2}{2}} $$</p>
<p>当 $0 \lt \theta \lt 2\pi$ 时，$\Theta$ 的边缘密度为</p>
<p>$$ g(\theta) = \int_0^{+\infty} q(r,\theta) \mathrm{d}r = \frac{1}{2\pi} $$</p>
<p>综上：</p>
<p>$$ f® = \begin{cases}<br>
r e^{-\frac{r^2}{2}} &amp; r \gt 0 \\<br>
0 &amp; 其他<br>
\end{cases} $$</p>
<p>$$ g(\theta) = \begin{cases}<br>
\frac{1}{2\pi} &amp; 0 \lt \theta \lt 2\pi \\<br>
0 &amp; 其他<br>
\end{cases} $$</p>
<h3 id="随机向量的数字特征">随机向量的数字特征</h3>
<h4 id="两个随机变量的均值公式">两个随机变量的均值公式</h4>
<p>设 $(X,Y)$ 的联合密度为 $p(x,y)$，令 $Z=f(X,Y)$，则有：</p>
<p>$$ E(Z) = E \left[ f(X,Y) \right] = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} f(x,y)p(x,y) \mathrm{d}x \mathrm{d}y $$</p>
<p>另外，也可以根据 $Z=f(x,y)$ 先求出 $Z$ 的密度 $p_Z(z)$ 然后再根据单个随机变量的均值公式</p>
<p>$$ E(Z) = \int_{-\infty}^{+\infty} z p_Z(z) \mathrm{d}z $$</p>
<p>求出 $Z$ 的均值。</p>
<h4 id="两个随机向量均值和方差的性质">两个随机向量均值和方差的性质</h4>
<p>设 $(X,Y)$ 的联合密度为 $p(x,y)$ ，$X,Y$ 的边缘密度分别为 $p_X(x), p_Y(y)$，由前面的知识我们已经知道，随机变量的均值和方差满足以下性质：</p>
<p>$$ \begin{aligned}<br>
E(X) &amp;= \int_{-\infty}^{+\infty} x p_X(x) \mathrm{d}x \\<br>
E(Y) &amp;= \int_{-\infty}^{+\infty} y p_Y(y) \mathrm{d}y \\<br>
D(X) &amp;= E \left( \left[ X-E(X) \right]^2 \right) = \int_{-\infty}^{+\infty} \left[ x-E(X) \right]^2 p_X(x) \mathrm{d}x \\<br>
D(Y) &amp;= E \left( \left[ Y-E(Y) \right]^2 \right) = \int_{-\infty}^{+\infty} \left[ y-E(Y) \right]^2 p_Y(y) \mathrm{d}y<br>
\end{aligned} $$</p>
<p>另一套由联合密度 $p(x,y)$ 给出的计算公式与上述公式形式上非常相近，只是一重积分变成了二重积分：</p>
<p>$$ \begin{aligned}<br>
E(X) &amp;= \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} x p(x,y) \mathrm{d}x\mathrm{d}y \\<br>
E(Y) &amp;= \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} y p(x,y) \mathrm{d}x\mathrm{d}y \\<br>
D(X) &amp;= \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} \left[ x-E(X) \right]^2 p(x,y) \mathrm{d}x\mathrm{d}y \\<br>
D(Y) &amp;= \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} \left[ y-E(Y) \right]^2 p(x,y) \mathrm{d}x\mathrm{d}y<br>
\end{aligned} $$</p>
<p>这几个公式的成立很容易证明，此处略去。</p>
<h4 id="两个随机变量的和的均值与方差">两个随机变量的和的均值与方差</h4>
<p>$$ E(X+Y) = E(X) + E(Y) \tag{1} $$</p>
<p>$$ D(X+Y) = D(X) + D(Y) + 2E \left( \left[X-E(X)\right] \left[Y-E(Y)\right]  \right) \tag{2} $$</p>
<p>当 $X,Y$ 独立时，有</p>
<p>$$ E(X \cdot Y) = E(X) \cdot E(Y) \tag{3} $$</p>
<p>$$ D(X+Y) = D(X) + D(Y) \tag{4} $$</p>
<p>式 $(1)$ 容易证明，略去。</p>
<p>证明 $(2)$ 式：</p>
<p>$$ \begin{aligned}<br>
D(X+Y) &amp;= E \left( \left[ (X+Y)-E(X+Y) \right]^2 \right) \\<br>
&amp;= E \left( \left[ \left[X-E(X)\right] + \left[Y-E(Y)\right] \right]^2 \right) \\<br>
&amp;= E \left( \left[X-E(X)\right]^2 + \left[Y-E(Y)\right]^2 + 2\left[X-E(X)\right]\left[Y-E(Y)\right] \right) \\<br>
&amp;= E \left( \left[X-E(X)\right]^2 \right) + E \left( \left[Y-E(Y)\right]^2 \right) + E \left( 2\left[X-E(X)\right]\left[Y-E(Y)\right] \right) \\<br>
&amp;= D(X) + D(Y) + 2E \left( \left[X-E(X)\right] \left[Y-E(Y)\right]  \right)<br>
\end{aligned} $$</p>
<p>证明 $(3)$ 式：</p>
<p>$$ \begin{aligned}<br>
E(X \cdot Y) &amp;= \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} xy p(x,y) \mathrm{d}x \mathrm{d}y \\<br>
&amp;= \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} xy p_X(x) p_Y(y) \mathrm{d}x \mathrm{d}y \quad (由于X,Y相互独立) \\<br>
&amp;= \int_{-\infty}^{+\infty} x p_X(x) \mathrm{d}x \int_{-\infty}^{+\infty} y p_Y(y) \mathrm{d}y \\<br>
&amp;= E(X) \cdot E(Y)<br>
\end{aligned} $$</p>
<p>证明 $(4)$ 式：</p>
<p>$$ \begin{aligned}<br>
&amp; E \left\{ \left[ X - E(X) \right] \left[ Y - E(Y) \right] \right\} \\<br>
&amp;= E \left\{ XY - X E(Y) - Y E(X) + E(X)E(Y) \right\} \\<br>
&amp;= E(XY) - E(X)E(Y) - E(X)E(Y) + E(X)E(Y) \\<br>
&amp;= E(XY) - E(X)E(Y) = 0<br>
\end{aligned} $$</p>
<h4 id="随机向量的均值和协方差">随机向量的均值和协方差</h4>
<p>称向量 $(E(X),E(Y))$ 为随机向量 $(X,Y)$ 的均值，称数值 $E \left\{ \left[ X- E(X) \right] \left[ Y - E(Y) \right] \right\}$ 为 $X,Y$ 的<strong>协方差</strong>。</p>
<p>协方差（斜方差）是二维随机向量 $(X,Y)$ 的重要数字特征，它刻画了 $X,Y$ 取值间的相互联系，通常采用记号：</p>
<p>$$ cov(X,Y) \overset{\mathrm{def}}{=} E \left\{ \left[ X- E(X) \right] \left[ Y - E(Y) \right] \right\} $$</p>
<p>或</p>
<p>$$ \sigma_{XY} \overset{\mathrm{def}}{=} E \left\{ \left[ X- E(X) \right] \left[ Y - E(Y) \right] \right\} $$</p>
<p>由前面的讨论可知：</p>
<p>$$ \begin{aligned}<br>
\sigma_{XY} &amp;= cov(X,Y) \\<br>
&amp;= \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} \left[ X- E(X) \right] \left[ Y - E(Y) \right] p(x,y) \mathrm{d}x \mathrm{d}y<br>
\end{aligned} $$</p>
<p>当 $X,Y$ 相互独立时，协方差 $\sigma_{XY} = 0$。随机变量独立是协方差为0的<strong>充分不必要条件</strong>。</p>
<p>与记号 $\sigma_{XY}$ 相对应，$D(X),D(Y)$ 也可分别记为 $\sigma_{XX},\sigma_{YY}$。</p>
<h4 id="随机向量的相关系数">随机向量的相关系数</h4>
<p><strong>定义</strong>：称</p>
<p>$$ \rho_{XY} = \frac{\sigma_{XY}}{\sqrt{\sigma_{XX}}\sqrt{\sigma_{YY}}} $$</p>
<p>为 $X,Y$ 的<strong>相关系数</strong>，在不引起混淆的情况下，简记为 $\rho$。</p>
<p>事实上，二维正态分布中的第五个参数 $\rho$ 就是 $\rho_{XY}$。</p>
<p>相关系数满足以下性质：</p>
<p>$$ \left| \rho \right| \le 1 $$</p>
<blockquote>
<p>💡 相关系数 $\rho$ 的实际意义是：它刻画了 $X,Y$ 之间的线性关系的近似程度。一般来说，$\left| \rho \right|$ 越接近 1，$X$ 与 $Y$ 越接近地有线性关系。<br>
要注意的是，$\rho$ 只刻画 $X$ 与 $Y$ 之间的线性关系，当 $X,Y$ 之间有很密切的曲线关系时，$\left| \rho \right|$ 的数值可能接近 1，也可能接近 0。</p>
</blockquote>
<h3 id="多维随机向量">多维随机向量</h3>
<p>对于一般的 $n$ 维随机向量，可仿照二维随机向量的情形进行讨论。</p>
<h4 id="联合密度与边缘密度">联合密度与边缘密度</h4>
<p>对于 $n$ 维随机向量 $\xi = ( X_1,X_2,\cdots,X_n )$ ，如果存在非负函数 $p(x_1,x_2,\cdots,x_n)$ ，使对于任意 $n$ 维长方体 $D = \left\{ (x_1,x_2,\cdots,x_n) \mid a_1 \lt x_1 \lt b_1,a_2 \lt x_2 \lt b_2,\cdots,a_n \lt x_n \lt b_n \right\}$ 均有：</p>
<p>$$ P \left\{ \xi \in D \right\} = \iint\limits_{D}\cdots \int p(x_1,x_2,\cdots,x_n) \mathrm{d}x_1 \mathrm{d}x_2 \cdots \mathrm{d}x_n $$</p>
<p>则称 $\xi = (X_1,X_2,\cdots,X_n)$ 是连续型的，并称 $p(x_1,x_2,\cdots,x_n)$ 为 $(X_1,X_2,\cdots,X_n)$ 的联合密度。</p>
<p>称 $(X_1,X_2,\cdots,X_n)$ 的一部分分量构成的向量——如 $(X_1,X_2)$ 的分布密度为边缘密度。特别地，每个分量 $X_i$的分布密度 $p_i(x_i)$ 当然也是边缘密度，称它们为<strong>单个密度</strong>。</p>
<p>$X_1$ 的单个密度可如下求得：</p>
<p>$$ p_1(x_1) = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} \cdots \int_{-\infty}^{+\infty} p(x_1,x_2,\cdots,x_n)\mathrm{d}x_2 \mathrm{d}x_3 \cdots \mathrm{d}x_n $$</p>
<p>$(X_1,X_2)$ 的边缘密度可如下求得：</p>
<p>$$ p_{12}(x_1,x_2) = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} \cdots \int_{-\infty}^{+\infty} p(x_1,x_2,\cdots,x_n)\mathrm{d}x_3 \mathrm{d}x_4 \cdots \mathrm{d}x_n $$</p>
<h4 id="独立性">独立性</h4>
<p>设 $X_1,X_2,\cdots,X_n$ 是 $n$ 个随机变量，如果对任意的 $a_i \lt b_i(i=1,2,\cdots,n)$ ，事件 $\left\{ a_1 \lt X_1 \lt b_1 \right\}, \left\{ a_2 \lt X_2 \lt b_2 \right\}, \cdots, \left\{ a_n \lt X_n \lt b_n \right\}$ 相互独立，则称 $X_1,X_2,\cdots,X_n$ 是<strong>相互独立</strong>的</p>
<p><strong>定理</strong>：设 $X_1,X_2,\cdots,X_n$ 的分布密度分别是 $p_1(x_1),p_2(x_2),\cdots,p_n(x_n)$ ，则 $X_1,X_2,\cdots,X_n$ 相互独立的<strong>充要条件</strong>是：$n$ 元函数</p>
<p>$$ p_1(x_1)p_2(x_2)\cdots p_n(x_n) $$</p>
<p>是 $(X_1,X_2,\cdots,X_n)$ 的联合密度。</p>
<h4 id="n-个随机变量的函数的分布">$n$ 个随机变量的函数的分布</h4>
<p>仍然采用<strong>分布函数法</strong>。设 $Z = f(X_1,X_2,\cdots,X_n)$ ，则 $Z$ 的分布为：</p>
<p>$$ \begin{aligned}<br>
F_Z(z) &amp;= P \left\{ f(X_1,X_2,\cdots,X_n) \le z \right\} \\<br>
&amp;= \iiint\limits_{f(x_1,x_2,\cdots,x_n) \lt z} p(x_1,x_2,\cdots,x_n) \mathrm{d}x_1 \mathrm{d}x_2 \cdots \mathrm{d}x_n<br>
\end{aligned} $$</p>
<p>$Z$ 的分布函数 $F_Z(z)$ 对 $z$ 求微分可以进一步求出 $Z$ 的密度函数 $p_Z(z)$。</p>
<h4 id="数字特征">数字特征</h4>
<h5 id="均值公式">均值公式</h5>
<p>$$ E \left[ f(X_1,X_2,\cdots,X_n) \right] = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} \cdots \int_{-\infty}^{+\infty} f(x_1,x_2,\cdots,x_n) p(x_1,x_2,\cdots,x_n) \mathrm{d}x_1 \mathrm{d}x_2 \cdots \mathrm{d}x_n $$</p>
<p>其中 $p(x_1,x_2,\cdots,x_n)$ 是 $(X_1,X_2,\cdots,X_n)$ 的联合密度。本公式要求右端的积分绝对收敛。</p>
<h5 id="均值与方差的性质">均值与方差的性质</h5>
<p>$$ E(X_1+X_2+\cdots+X_n) = E(X_1) + E(X_2) + \cdots + E(X_n) $$</p>
<p>当 $X_1,X_2,\cdots,X_n$ 相互独立时，有：</p>
<p>$$ \begin{aligned}<br>
E(X_1 X_2 \cdots X_n) &amp;= E(X_1) E(X_2) E(X_n) \\<br>
D(X_1+X_2+\cdots+x_n) &amp;= D(X_1) + D(X_2) + \cdots + D(X_n)<br>
\end{aligned} $$</p>
<h5 id="协方差与协差阵">协方差与协差阵</h5>
<p>对于 $i \neq j$ ，$\sigma_{ij}$ 是第 $i$ 个分量 $X_i$ 与第 $j$ 个分量 $X_j$ 的协方差；而 $\sigma_{ii}$ 是第 $i$ 个分量 $X_i$ 的方差。称矩阵：</p>
<p>$$ \begin{bmatrix}<br>
\sigma_{11} &amp; \sigma_{12} &amp; \cdots &amp; \sigma_{1n} \\<br>
\sigma_{21} &amp; \sigma_{22} &amp; \cdots &amp; \sigma_{2n} \\<br>
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>
\sigma_{n1} &amp; \sigma_{n2} &amp; \cdots &amp; \sigma_{nn} \\<br>
\end{bmatrix} $$</p>
<p>为 $(X_1,X_2,\cdots,X_n)$ 的协差阵，记为 $\mathbf{\Sigma}$。$\mathbf{\Sigma}$ 显然是对称矩阵，且可以验证 $\mathbf{\Sigma}$ 是非负定的。</p>
<h5 id="相关系数与相关阵">相关系数与相关阵</h5>
<p>$$ \rho_{ij} = \frac{\sigma_{ij}}{\sqrt{\sigma_{ii}}\sqrt{\sigma_{jj}}} \quad (i=1,2,\cdots,n; \; j=1,2,\cdots,n) $$</p>
<p>对于 $i \neq j$ ，$\rho_{ij}$ 是 $X_i,X_j$ 的相关系数。同时有 $\rho_{ii}=1$。称矩阵</p>
<p>$$ \begin{bmatrix}<br>
\rho_{11} &amp; \rho_{12} &amp; \cdots &amp; \rho_{1n} \\<br>
\rho_{21} &amp; \rho_{22} &amp; \cdots &amp; \rho_{2n} \\<br>
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>
\rho_{n1} &amp; \rho_{n2} &amp; \cdots &amp; \rho_{nn} \\<br>
\end{bmatrix} $$</p>
<p>为 $(X_1,X_2,\cdots,X_n)$ 的相关阵，记为 $\mathbf{R}$。显然，$\mathbf{R}$ 是对称矩阵。</p>
<h5 id="n-维分布函数">$n$ 维分布函数</h5>
<p><strong>定义</strong>：设 $\xi = (X_1,X_2,\cdots,X_n)$ 是 $n$ 维随机向量，称 $n$ 维函数 $F(x_1,x_2,\cdots,x_n)=P \left\{ X_1\le x_1,X_2\le x_2,\cdots,X_n\le x_n \right\}$ 为 $\xi$ 的<strong>分布函数</strong>。</p>
<p>如果 $\xi$ 的分布密度为 $p(x_1,x_2,\cdots,x_n)$ ，则有：</p>
<p>$$ F(x_1,x_2,\cdots,x_n) = \int_{-\infty}^{x_1} \int_{-\infty}^{x_2} \cdots \int_{-\infty}^{x_n} p(u_1,u_2,\cdots,u_n) \mathrm{d}u_1 \mathrm{d}u_2 \cdots \mathrm{d}u_n $$</p>
<h3 id="大数定律和中心极限定理">大数定律和中心极限定理</h3>
<h4 id="大数定律">大数定律</h4>
<p>设 $X_1,X_2,\cdots,X_n,\cdots$ 是独立同分布的随机变量列，且 $E(X_1),D(X_1)$ 存在，则对任意的 $\varepsilon \gt 0$，有：</p>
<p>$$ \lim_{n \to \infty}P \left\{ \left| \frac{S_n}{n} - E(X_1) \right| \ge \varepsilon \right\} = 0 $$</p>
<p>这说明，<strong>只要 $n$ 足够大，算术平均值 $\frac{1}{n} (X_1+X_2+\cdots+X_n)$ 将无限接近于期望</strong>。这是整个概率论所基于的基本定理。</p>
<h4 id="强大数定律">强大数定律</h4>
<p>经过细致的研究发现，只要 $E(X_1)$ 存在，不管 $D(X_1)$ 是否存在，大数定律依然成立，而且可以得到更强的结论：</p>
<p>$$ P \left\{ \lim_{n\to\infty} \frac{S_n}{n} =E(X_1) \right\} = 1 $$</p>
<p>将该式称为强大数定律。</p>
<h4 id="中心极限定理">中心极限定理</h4>
<p>设 $X_1,X_2,\cdots,X_n,\cdots$ 是独立同分布的随机变量列，且 $E(X_1),D(X_1)$ 存在，$D(X_1) \neq 1$，则对一切实数 $a \lt b$，有：</p>
<p>$$ \lim_{n\to\infty}P \left\{ a \lt \frac{S_n-n E(X_1)}{\sqrt{n D(X_1)}} \lt b \right\} = \int_{a}^{b} \frac{1}{\sqrt{2\pi}} e^{-\frac{u^2}{2}} \mathrm{d}u $$</p>
<p>这里，$S_n = X_1+X_2+\cdots+X_n$</p>
<p>如果记 $\overline{X} = \frac{1}{n}(X_1+X_2+\cdots+X_n)$，上式也可写成：</p>
<p>$$ \lim_{n\to\infty} P \left\{ a \lt \frac{\overline{X}-E(X_1)}{\sqrt{D(X_1)/n}} \lt b \right\} = \int_{a}^{b} \frac{1}{\sqrt{2\pi}} e^{-\frac{u^2}{2}} \mathrm{d}u $$</p>
<p>这表明，只要 $n$ 足够大，随机变量 $\frac{\overline{X}-E(X_1)}{\sqrt{D(X_1)/n}}$ 就近似地服从标准正态分布，从而 $\overline{X}$ 近似地服从正态分布。故<strong>中心极限定理表达了正态分布在概率论中的特殊地位</strong>，尽管 $X_1$ 的分布是任意的，但只要 $n$ 充分大，算数平均值 $\overline{X}$ 的分布却是近似正态的。</p>
<h2 id="第五章-统计估值">第五章 统计估值</h2>
<h3 id="总体与样本">总体与样本</h3>
<p><strong>样本定义</strong>：称随机变量 $X_1,X_2,\cdots,X_n$ 为来自总体 $X$ 的容量为 $n$ 的样本，如果 $X_1,X_2,\cdots,X_n$ <strong>相互独立</strong>，而且每个 $X_i$ 与 $X$ 有相同的概率分布。这时，若 $X$ 有分布密度 $p(x)$ ，则常简称 $X_1,X_2,\cdots,X_n$ 是来自总体 $p(x)$ 的样本。</p>
<p><strong>定理</strong>：若 $X_1,X_2,\cdots,X_n$ 是来自总体的 $p(x)$ 的样本，则 $(X_1,X_2,\cdots,X_n)$ 有联合密度 $p(x_1)p(x_2)\cdots p(x_n)$ 。</p>
<h3 id="分布函数与分布密度的估计">分布函数与分布密度的估计</h3>
<h4 id="经验分布函数">经验分布函数</h4>
<p>设 $X$ 是一个随机变量，具有一系列样本值 $x_1,x_2,\cdots,x_n$ ，称函数</p>
<p>$$ F_n(x) = \frac{v_n}{n} $$</p>
<p>为 $X$ 的经验分布函数。其中，$v_n$ 为 $x_1,x_2,\cdots,x_n$ 中不超过 $x$ 的个数。</p>
<h4 id="经验分布密度">经验分布密度</h4>
<p>经验分布密度可采用经验分布函数进行估计。</p>
<p>当 $h$ 足够小时，易知</p>
<p>$$ p(x)=\frac{F(x+h)-F(x-h)}{2h} $$</p>
<p>对应地，可以得到：</p>
<p>$$ \hat{p_n}(x)=\frac{F_n(x+h)-F_n(x-h)}{2h} $$</p>
<p>具体方法包括：</p>
<h5 id="1-直方图法">(1) 直方图法</h5>
<p>作直方图，当分组数足够大，分组间距足够小时，所有小矩形顶端的连线近似刻画了分布密度函数</p>
<h5 id="2-核估计法">(2) 核估计法</h5>
<p><strong>核函数定义</strong>：设 $K(x)$ 是非负函数且 $\int_{-\infty}^{+\infty}K(x)\mathrm{d}x = 1$ ，则称 $K(x)$ 是核函数。核函数有很大的选择自由，例如：</p>
<p>$$ K_0(x) = \begin{cases}<br>
1/2 \quad &amp; -1\le x\lt 1 \\<br>
0 \quad &amp; \text{其他}<br>
\end{cases} $$</p>
<p>$$ K_1(x) = \begin{cases}<br>
1 \quad &amp; -1/2 \le x \lt 1/2 \\<br>
0 \quad &amp; \text{其他}<br>
\end{cases} $$</p>
<p>$$ K_2(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2} $$</p>
<p>$$ K_3(x) = \frac{1}{\pi(1+x^2)} $$</p>
<p>$$ K_4(x) = \frac{1}{2\pi}\left( \frac{\sin(x/2)}{x/2} \right)^2 $$</p>
<p><strong>核估计</strong>：称函数</p>
<p>$$ \hat{p_n}(x) = \frac{1}{nh}\sum_{i=1}^{n}K \left( \frac{x-x_i}{h} \right) $$</p>
<p>为 $p(x)$ 的核估计。其中，$h$ 为一个较小的常数（参考直方图法中的分组宽度），$x_i$ 为样本值。</p>
<blockquote>
<p>可以这样理解核估计中核函数 $K \left( \frac{x-x_i}{h} \right)$ 的作用：<br>
随机变量 $X$ 在 $x$ 处的概率由核函数确定，核函数将散落在 $x$ 附近一定范围内（若干单位个 $h$ 值）的所有样本点 $x_i$ 作为 $P\{X=x\}$ 的一部分权重。而 $\displaystyle \sum_{i=1}^{n}K \left( \frac{x-x_i}{h} \right)$ 即为所有样本点对 $P\{X=x\}$ 贡献权重的总和。</p>
</blockquote>
<h5 id="3-最近邻估计法">(3) 最近邻估计法</h5>
<h3 id="最大似然估计">最大似然估计</h3>
<p><strong>适用情况</strong>：已知随机变量的分布类型，但不知道参数的值，在此种情况下要得到分布密度可采用最大似然估计法。</p>
<p>例如：已知随机变量 $X$ 满足正态分布，但不知道 $\mu,\sigma^2$ 的值，此时可采用最大似然估计法。</p>
<p><strong>似然函数</strong>：假设已知随机变量 $X$ 的分布密度为 $p(x;\theta_1,\theta_2,\cdots,\theta_m)$ ，但不知道其中的参数 $\theta_1,\theta_2,\cdots,\theta_m$ ，现给定样本值 $x_1,x_2,\cdots,x_n$ ，称函数</p>
<p>$$ L_n(x_1,x_2,\cdots,x_n;\theta_1,\theta_2,\cdots,\theta_m)=\prod_{i=1}^{n}p(x_i;\theta_1,\theta_2,\cdots,\theta_m)$$</p>
<p>为样本 $x_1,x_2,\cdots,x_n$ 的似然函数。</p>
<p><strong>最大似然估计</strong>：如果 $L_n(x_1,x_2,\cdots,x_n;\theta_1,\theta_2,\cdots,\theta_m)$ 在 $\hat{\theta}_1,\hat{\theta}_2,\cdots,\hat{\theta}_m$ 达到最大值，则称 $\hat{\theta}_1,\hat{\theta}_2,\cdots,\hat{\theta}_m$ 分别是 $\theta_1,\theta_2,\cdots,\theta_m$ 的最大似然估计。</p>
<p>由于 $\ln L_n$ 与 $L_n$ 同时达到最大值，为了简化计算，常常采用 $\ln L_n$ 来描述。那么如何才能使得 $\ln L_n$ 达到最大值呢？可以利用“最大值点的一阶偏微分为0”这一性质，列出<strong>似然方程组</strong>：</p>
<p>$$ \left\{ \begin{aligned}<br>
\frac{\partial\ln L_n}{\partial \theta_1} &amp;= 0 \\<br>
\frac{\partial\ln L_n}{\partial \theta_2} &amp;= 0 \\<br>
\cdots \cdots \\<br>
\frac{\partial\ln L_n}{\partial \theta_m} &amp;= 0 \\<br>
\end{aligned} \right. $$</p>
<p>如此便可解得 $\hat{\theta}_1,\hat{\theta}_2,\cdots,\hat{\theta}_n$ 。</p>
<h3 id="期望和方差的点估计">期望和方差的点估计</h3>
<p>有时并不需要求得密度函数，而只需获得某些数字特征，这类估计称作点估计。</p>
<h4 id="期望的点估计">期望的点估计</h4>
<p>利用 $\displaystyle \overline{X}=\frac{X_1+X_2+\cdots+X_n}{n}$ 来估计期望 $E(x)$ <strong>不存在系统偏差</strong>。即：</p>
<p>$$ E(\overline{X})=E(X) $$</p>
<p>证明：</p>
<p>$$ \begin{aligned}<br>
E(\overline{X}) &amp;= E \left( \frac{X_1+X_2+\cdots+X_n}{n} \right) \\<br>
&amp;= \frac{1}{n}\left[ E(X_1)+E(X_2)+\cdots+E(X_n) \right] \\<br>
&amp;= E(X)<br>
\end{aligned} $$</p>
<p>同理还可以得到:</p>
<p>$$ D(\overline{X})=\frac{D(X)}{n} $$</p>
<p>这说明，样本数量 $n$ 越大，用 $\overline{X}$ 来估计 $E(X)$ 的波动越小，即估计越优良。</p>
<h4 id="方差的点估计">方差的点估计</h4>
<p>利用 $\displaystyle S^2=\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\overline{x})^2$ 来估计方差 $D(X)$ 不存在系统偏差。即：</p>
<p>$$ E(S^2) = D(X) $$</p>
<p>需要注意，我们习惯使用的 $\displaystyle \frac{1}{n}\sum_{i=1}^{n}(x_i-\overline{x})^2$ 并不是方差的无偏估计量。</p>
<h3 id="期望的置信区间">期望的置信区间</h3>
<p>期望的点估计只是得到了期望的一个近似值，那么该近似值 $\overline{X}$ 与真实值 $E(X)$ 到低相差多少呢？这就涉及到<strong>区间估计问题</strong>。</p>
<h4 id="已知方差，对期望进行区间估计">已知方差，对期望进行区间估计</h4>
<p>对于任意随机变量 $X$ ，根据中心极限定理可知，随机变量</p>
<p>$$ \eta = \frac{\overline{X}-E(X)}{\sqrt{\frac{D(X)}{n}}} $$</p>
<p>是服从标准正态分布的。查表可以得到</p>
<p>$$ P \left\{ \left| \eta \right|\le 1.96 \right\}=0.95 $$</p>
<p>也即 $E(X)$ 落在区间</p>
<p>$$ \left[ \overline{X}-1.96 \sqrt{\frac{D(X)}{n}},\;\overline{X}+1.96 \sqrt{\frac{D(X)}{n}} \right] $$</p>
<p>以内的概率为 $95%$ 。</p>
<p>这就是 $E(X)$ 的<strong>置信区间</strong>，<strong>置信度</strong>为 $95%$ 。</p>
<h4 id="未知方差，对期望进行区间估计">未知方差，对期望进行区间估计</h4>
<p>未知方差时，不能使用上述的置信区间公式，但我们自然会想到利用方差的无偏估计量 $S^2$ 来替代方差，即研究随机变量</p>
<p>$$ T = \frac{\overline{X}-E(X)}{\sqrt{S^2/n}} $$</p>
<p>的分布。经过复杂的推导发现，随机变量 $T$ 服从 $n-1$ 个自由度的 $t$ 分布：</p>
<p>$$ p_n(t)=\frac{\Gamma(n/2)}{\sqrt{(n-1)\pi}\Gamma((n-1)/2)}\left( 1+\frac{t^2}{n-1} \right)^{-n/2} $$</p>
<p>这样就得到了 $E(X)$ 的置信区间，如下：</p>
<p>$$ \left[ \overline{X}-\lambda \sqrt{\frac{S^2}{n}},\;\overline{X}+\lambda \sqrt{\frac{S^2}{n}} \right] $$</p>
<p>其中 $\lambda$ 可以通过查找 $t$ 分布的<strong>临界值表</strong>获得。</p>
<h3 id="方差的置信区间">方差的置信区间</h3>
<p>以下讨论只适用于<strong>服从正态分布</strong>的随机变量。</p>
<p>从计算期望的置信区间中我们受到如下启发：</p>
<blockquote>
<p>要求某个量的置信区间，我们首先通过该量构造一个特殊的随机变量 $\eta$，使得 $\eta$ 的分布与所研究的随机变量 $X$ 无关，而只与样本容量 $n$ 有关。然后通过给定的置信度从 $\eta$ 的分布的临界值表中反解出置信区间。</p>
</blockquote>
<p>我们构造随机变量 $\displaystyle \eta=\frac{(n-1)S^2}{\sigma^2}$ ，得出其分布为 $n-1$ 个自由度的 $\chi^2$ 分布，即：</p>
<p>$$ p(u)=\begin{cases}<br>
\frac{1}{2^{\frac{n-1}{2}}\Gamma(\frac{n-1}{2})} u^{(n-3)/2} e^{-u/2} \quad &amp; u\gt 0 \\<br>
0 &amp; u\le 0\\<br>
\end{cases} $$</p>
<p>进而得出 $\sigma^2$ 的置信区间为：</p>
<p>$$ \left[ \frac{(n-1)S^2}{\lambda_2},\;\frac{(n-1)S^2}{\lambda_1} \right] $$</p>
<p>也即：</p>
<p>$$ \left[ \frac{\sum_{i=1}^{n}(X_i- \overline{X})^2}{\lambda_2},\; \frac{\sum_{i=1}^{n}(X_i- \overline{X})^2}{\lambda_1} \right] $$</p>
<p>式中 $\lambda_1,\lambda_2$ 可以通过查找 $\chi^2$ 分布的临界值表得到。</p>
<h2 id="第六章-假设检验">第六章 假设检验</h2>
<h3 id="问题的提法">问题的提法</h3>
<p><strong>例 1</strong>：某厂有一批产品，共 200 件，须经检验合格才能出厂，按国家标准，次品率不得超过 1% ，今在其中任意抽取 5 件，发现这 5 件含有次品。问这批产品能否出厂？</p>
<p>从直觉上看，这批产品当然是不能出厂的，但为什么呢？</p>
<p><strong>例 2</strong>：怎样根据一个随机变量的样本值，判断该随机变量是否服从正态分布 $N(\mu,\sigma^2)$？</p>
<p><strong>假设检验问题</strong>：这类问题中都隐含着一种“假设”或“看法”，例 1 中的假设是：次品率 $p \le 0.01$，例 2 中的假设是：该随机变量服从正态分布 $N(\mu,\sigma^2)$ ，现在我们要检验这些假设是否正确，这类问题称为<strong>假设检验问题</strong>。</p>
<p>回到例 1：要检验的假设是 $p\le 0.01$ ，如果假设成立，我们看看会出现什么后果。此时，假设有 200 件样品，那么其中最多有 2 件次品，任意抽取 5 件，我们来求 5 件中无次品的概率：</p>
<p>$$ P \left\{ \text{无次品} \right\} \ge \frac{C_{198}^5}{C_{200}^5} \ge 0.95 $$</p>
<p>于是，任抽 5 件，出现次品的概率 $\le 1-0.95=0.05$ 。这说明，如果次品率 $\le 0.01$ ，那么抽取 5 件样品，出现次品的机会是很小的，平均在 100 次抽样中，出现不到 5 次。而现在的事实是，在一次抽样实践中，竟然就发生了这种小概率事件，这是不合理的！因此假设 $p\le 0.01$ 是不能接受的。</p>
<blockquote>
<p>注：通常把概率不超过 0.05 的事件当做“小概率事件”，有时也把概率不超过 0.01 的事件当做小概率事件。</p>
</blockquote>
<p>以上分析过程可概括为<strong>概率性质的反证法</strong>。</p>
<h3 id="一个正态总体的假设检验">一个正态总体的假设检验</h3>
<p>设 $X \sim N(\mu,\sigma^2)$ ，关于它的假设检验问题，主要是下列四种：</p>
<ol>
<li>已知方差 $\sigma^2$ ，检验假设 $H_0: \mu = \mu_0$ （$\mu_0$ 是已知数）。</li>
<li>未知方差 $\sigma^2$ ，检验假设 $H_0: \mu = \mu_0$ （$\mu_0$ 是已知数）。</li>
<li>未知期望 $\mu$ ，检验假设 $H_0: \sigma^2 = \sigma_0^2$ （$\sigma_0$ 是已知数）。</li>
<li>未知期望 $\mu$ ，检验假设 $H_0: \sigma^2 \le \sigma_0^2$ （$\sigma_0$ 是已知数）。</li>
</ol>
<p>以下分别介绍。</p>
<h4 id="1-已知方差，检验期望">1. 已知方差，检验期望</h4>
<p>我们首先假设 $H_0$ 成立，看在该条件下会不会产生不合理的现象。</p>
<p>在 $\mu=\mu_0$ 的条件下，有 $X \sim N(\mu_0,\sigma^2)$ ，假设有样品 $X_1,X_2,\cdots,X_n$ ，由中心极限定理可知：</p>
<p>$$ U = \frac{\overline{X}-\mu_0}{\sqrt{\sigma^2/n}}  \sim  N(0,1) $$</p>
<p>查正态分布表可知：</p>
<p>$$ P \left\{ \left| \frac{\overline{X}-\mu_0}{\sqrt{\sigma^2/n}} \right| \gt 1.96 \right\} = 0.05 $$</p>
<p>该式描述了一个小概率事件，也就是说，如果我们用样本 $X_1,X_2,\cdots,X_n$ 实际计算出来的 $\overline{X}$ 满足该式，那么假设 $H_0$ 就是不合理的，则假设不成立，也称为<strong>假设不相容</strong>。</p>
<blockquote>
<p>事实上，以上计算过程完全<strong>等效于求置信区间问题</strong>。其等效解法为：先根据 $\sigma^2$ 和样本 $X_1,X_2,\cdots,X_n$ 求出 $\mu$ 的置信区间，如果 $\mu_0$ 在该区间内，则认为假设 $H_0$ 成立，否则认为假设不成立。</p>
</blockquote>
<p><strong>两类错误</strong>：从以上的分析过程中我们可以看到，当一个事件为小概率事件时，我们就认为它绝对不可能发生，这显然是不合理的，有时会造成错误：</p>
<p>当一个假设实际上是成立的，我们根据对样本的计算却判定其不成立，即犯了“以真为假”的错误，这种错误称为<strong>第一类错误</strong>。</p>
<p>反之，当一个假设实际上是不成立的，我们根据对样本的计算判定其成立，即犯了“以假为真”的错误，这种错误称为<strong>第二类错误</strong>。</p>
<h4 id="2-未知方差，检验期望">2. 未知方差，检验期望</h4>
<p>可转化为求置信区间问题，我们前面已经讲述过了，此处不再赘述。关键点是：构造随机变量</p>
<p>$$ T = \frac{\overline{X}-\mu}{\sqrt{S^2/n}} $$</p>
<p>$T$ 应符合 $n-1$ 个自由度的 $t$ 分布。</p>
<h4 id="3-未知期望，检验方差">3. 未知期望，检验方差</h4>
<h4 id="4-未知期望，检验方差的上限">4. 未知期望，检验方差的上限</h4>
<p>同样采用求置信区间的思路，关键点是：构造随机变量</p>
<p>$$ W = \frac{(n-1)S^2}{\sigma^2} $$</p>
<p>$W$ 应符合 $n-1$ 个自由度的 $\chi^2$ 分布。</p>
<h3 id="两个正态总体的假设检验">两个正态总体的假设检验</h3>
<p>在实际问题中，除了遇到一个总体的检验问题，还常遇到两个总体的比较问题。</p>
<p>设 $X \sim N(\mu_1,\sigma_1^2)$ ，$Y \sim N(\mu_2,\sigma_2^2)$ ，且 $X, Y$ 相互独立，主要研究以下四类问题：</p>
<ol>
<li>未知 $\sigma_1^2,\sigma_2^2$，但知道 $\sigma_1^2=\sigma_2^2$ ，检验假设 $H_0:\mu_1=\mu_2$</li>
<li>未知 $\mu_1,\mu_2$，检验假设 $H_0:\sigma_1^2 = \sigma_2^2$</li>
<li>未知 $\mu_1,\mu_2$，检验假设 $H_0:\sigma_1^2 \le \sigma_2^2$</li>
<li>未知 $\sigma_1^2,\sigma_2^2$，但知道 $\sigma_1^2 \ne \sigma_2^2$ ，检验假设 $H_0:\mu_1=\mu_2$</li>
</ol>
<p>以下分别讨论。</p>
<p><strong>1. 未知 $\sigma_1^2,\sigma_2^2$ ，但知道 $\sigma_1^2=\sigma_2^2$ ，检验假设 $H_0:\mu_1=\mu_2$</strong></p>
<p>设 $X_1,X_2,\cdots,X_{n_1}$ 来自总体 $N(\mu_1,\sigma_1^2)$，$Y_1,Y_2,\cdots,Y_{n_2}$ 来自总体 $N(\mu_2,\sigma_2^2)$，且 $X,Y$ 间相互独立。现已知 $\sigma_1^2=\sigma_2^2$，如何检验假设 $H_0:\mu_1=\mu_2$？</p>
<p>类比前面的研究方法，我们构造一个特殊的统计量：</p>
<p>$$ \widetilde{T} = \frac{(\overline{X}-\overline{Y})-(\mu_1-\mu_2)}{\sqrt{(n_1-1)S_1^2+(n_2-1)s_2^2}} \cdot \sqrt{\frac{n_1 n_2 (n_1+n_2-2)}{n_1+n_2}} $$</p>
<p>数学上可以证明 $\widetilde{T}$ 服从 $n_1+n_2-2$ 个自由度的 $t$ 分布。</p>
<p><strong>2. 未知 $\mu_1,\mu_2$ ，检验假设 $H_0:\sigma_1^2 = \sigma_2^2$</strong></p>
<p>构造特殊的统计量：</p>
<p>$$ \widetilde{F} = \frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2} $$</p>
<p>数学上可以证明 $\widetilde{F}$ 服从自由度为 $n_1-1, n_2-1$ 的 $F$ 分布，其中，$n_1-1,n_2-1$ 分别称为<strong>第一自由度</strong>和<strong>第二自由度</strong>。</p>
<p><strong>3. 未知 $\mu_1,\mu_2$ ，检验假设 $H_0:\sigma_1^2 \le \sigma_2^2$</strong></p>
<p>同 2.</p>
<p><strong>4. 未知 $\sigma_1^2,\sigma_2^2$ ，但知道 $\sigma_1^2 \ne \sigma_2^2$ ，检验假设 $H_0:\mu_1=\mu_2$</strong></p>
<p>这是著名的 Behrens-Fisher 问题。其解决方法如下：</p>
<p>设 $X_1,X_2,\cdots,X_{n_1}$ 来自总体 $N(\mu_1,\sigma_1^2)$ ，$Y_1,Y_2,\cdots,Y_{n_2}$ 来自总体 $N(\mu_2,\sigma_2^2)$ ，且 $X,Y$ 间相互独立。</p>
<p>$\overline{X}, \overline{Y}, S_1^2, S_2^2$ 分别表示样本 1、2 的均值，样本 1、2 的方差。易知：</p>
<p>$$ \overline{X}-\overline{Y}  \sim  N \left( \mu_1-\mu_2,\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2} \right) $$</p>
<p>于是：</p>
<p>$$ \frac{\overline{X}-\overline{Y}-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}} \sim  N(0,1) $$</p>
<p>在零假设 $H_0:\mu_1=\mu_2$ 下</p>
<p>$$ \xi \triangleq \frac{\overline{X}-\overline{Y}}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}  \sim  N(0,1) $$</p>
<p>可见 $\left| \xi \right|$ 值太大时应拒绝 $H_0$ ，但由于 $\sigma_1^2, \sigma_2^2$ 是未知的，自然想到用 $S_1^2, S_2^2$ 分别代替，得到统计量：</p>
<p>$$ T = \frac{\overline{X}-\overline{Y}}{\sqrt{\frac{S_1^2}{n_1}+\frac{S_2^2}{n_2}}} $$</p>
<p>然而，$T$ 的精确分布依然相当复杂，且依赖于比值 $\frac{\sigma_1^2}{\sigma_2^2}$ 。幸运的是，数学上可以证明，统计量 $T$ 近似服从 $m$ 个自由度的 $t$ 分布，这个 $m$ 乃是与以下 $m^\ast$ 最接近的整数：</p>
<p>$$ m^\ast = \frac{\left( \frac{1}{n_1}S_1^2+\frac{1}{n_2}S_2^2 \right)^2}{\frac{1}{n_1-1}\left( \frac{S_1^2}{n_1} \right)^2 + \frac{1}{n_2-1}\left( \frac{S_2^2}{n_2} \right)^2} $$</p>
<p>利用 $t$ 分布表，找临界值 $\lambda$ 满足 $P(|T|&gt;\lambda)=a$ ，于是当且仅当 $|T|&gt;\lambda$ 时拒绝 $H_0: \mu_1=\mu_2$</p>
<h2 id="第七章-回归分析">第七章 回归分析</h2>
<p>回归分析是用来处理多个变量之间<strong>相关关系</strong>的一种数学方法。<strong>相关关系</strong>不同于<strong>函数关系</strong>，在相关关系中，多个变量之间明显相关，但并不具有完全确定性的关系，例如人的身高和体重，虽然凭借身高并不能精确确定体重，但总体来说有“身高者，体也重”的关系。</p>
<h3 id="一元线性回归">一元线性回归</h3>
<h4 id="经验公式与最小二乘法">经验公式与最小二乘法</h4>
<p>对于有一定关系的两个变量 $X,Y$ ，在观测中得到若干组数据 $(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)$，我们怎样获取 $X,Y$ 之间的经验公式呢？</p>
<p><strong>step 1</strong>：作出<strong>散点图</strong>，大致确定经验公式的形式。若散点图大致为线性关系，那么我们可以得到如下经验公式：</p>
<p>$$ \hat{y} = a + bx $$</p>
<p>这里，在 $y$ 上方加“$\hat{}$”，是为了区别于 $Y$ 的实际值 $y$，因为 $y$ 代表着其与 $x$ 之间的函数关系，而观测值一般不具有严格的函数关系。</p>
<p><strong>step 2</strong>：求出参数 $a,b$</p>
<p>上述关系式：</p>
<p>$$ \hat{y} = a + bx $$</p>
<p>称为<strong>回归方程</strong>。我们的目的是要找到合适的参数 $a,b$ 使得<strong>回归方程所代表的直线总体最接近所有的散点</strong>。</p>
<p>我们如何来刻画一条直线与所有散点之间的总体接近程度呢？可以通过以下统计量：</p>
<p>$$ \sum_{i=1}^{n} \left[ y_i - (a + b x_i) \right]^2 $$</p>
<blockquote>
<p>该统计量的几何意义是点 $(x_i,y_i)$ 沿着 $y$ 轴的方向到直线的距离，而不是到直线的垂直距离！</p>
</blockquote>
<p>上述统计量随着 $a,b$ 的变化而变化，是关于 $a,b$ 的二元函数，记为 $Q(a,b)$：</p>
<p>$$ Q(a,b) = \sum_{i=1}^{n} \left[ y_i - (a + b x_i) \right]^2 $$</p>
<p>我们的目的是找到两个数 $\hat{a},\hat{b}$，使二元函数 $Q(a,b)$ 在 $a = \hat{a},b=\hat{b}$ 处达到最小</p>
<p>由于 $Q(a,b)$ 是 $n$ 个平方之和，所以使 $Q(a,b)$ 最小的原则称为<strong>平方和最小原则</strong>，习惯上称为<strong>最小二乘原则</strong>。$a,b$ 的值可以通过以下方程组求得：</p>
<p>$$ \left\{<br>
\begin{aligned}<br>
\frac{\partial Q}{\partial a} &amp;= -2 \sum_{i=1}^{n} \left[ y_i - (a + b x_i) \right] = 0 \\<br>
\frac{\partial Q}{\partial b} &amp;= -2 \sum_{i=1}^{n} \left[ y_i - (a + b x_i) \right] \cdot x_i = 0<br>
\end{aligned}<br>
\right. $$</p>
<p>解得：</p>
<p>$$ \left\{<br>
\begin{aligned}<br>
b &amp;= \frac{\sum\limits_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{\sum\limits_{i=1}^{n}(x_i-\bar{x})^2} \\<br>
a &amp;= \bar{y} - b \bar{x}<br>
\end{aligned}<br>
\right. $$</p>
<h5 id="当相关关系不是线性关系时如何使用最小二乘法？">当相关关系不是线性关系时如何使用最小二乘法？</h5>
<p>采用适当的转化，构造原变量的生成变量，使得生成变量之间具有线性关系。</p>
<p>例如：变量 $X,Y$ 有如下相关关系：</p>
<p>$$ y = A e^{-B/x} $$</p>
<p>显然 $y$ 与 $x$ 之间的关系不是线性的。我们对等式两边取自然对数：</p>
<p>$$ \ln y = \ln A - \frac{B}{x} $$</p>
<p>令</p>
<p>$$ \begin{aligned}<br>
y^\ast &amp;= \ln y \\<br>
x^\ast &amp;= \frac{1}{x}<br>
\end{aligned} $$</p>
<p>则两个新变量 $y^\ast,x^\ast$ 之间的关系便是线性的了，我们将 $x,y$ 的观测数值转化为这两种形式即可。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>请我一杯咖啡吧！</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechatpay.png" alt="Henry 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="/images/alipay.jpg" alt="Henry 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          <div class="post-tags">
              <a href="/tags/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/" rel="tag"><i class="fa fa-tag"></i> 概率统计</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/20d9a268/" rel="prev" title="矩阵求导术">
                  <i class="fa fa-angle-left"></i> 矩阵求导术
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/66517499/" rel="next" title="线性代数的本质">
                  线性代数的本质 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">银河系ICP备 </a><a href="https://beian.mps.gov.cn/#/query/webSearch?code=42" rel="noopener" target="_blank">42号 </a>
  </div>
  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Henry</span>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/hzhu212" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.8.0/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"hzhu212","repo":"_blog_comment","client_id":"718c67973a0818c37f02","client_secret":"f815ebc1b572a2af9f809a5e8373d1632faa133f","admin_user":"hzhu212","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":null,"js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.8.0/dist/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"9aec82f885efbf00f219ad7c6da38ab3"}</script>
<script src="/js/third-party/comments/gitalk.js" defer></script>

</body>
</html>
